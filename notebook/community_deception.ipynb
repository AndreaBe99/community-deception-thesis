{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"673bb049-4b2f-485d-917a-9ee37a24dc02","_uuid":"0f32c4fd-e251-4197-9445-e1dcbaf2350f","id":"p0PM-10o4qNq","trusted":true},"source":["# Community Deception"]},{"cell_type":"markdown","metadata":{},"source":["Connect Google Drive to access the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9826e4bc-2669-4e64-9163-59a00fd69e75","_uuid":"24a13315-6d17-45bb-a1aa-da091f1bf4c4","collapsed":false,"id":"ZInwz0n74vdY","jupyter":{"outputs_hidden":false},"outputId":"2c64d1b1-851d-4e69-a303-7e9520f08193","trusted":true},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"_cell_guid":"767eccaf-5a8b-4a3d-8fd9-a6c7b0e67d80","_uuid":"0f6e823a-2475-4d31-9c78-96fbbb666d33","id":"fMmiVKrL4qNt","trusted":true},"source":["## Install Pytorch Geometric"]},{"cell_type":"markdown","metadata":{"_cell_guid":"92deff0d-cd46-44c5-8422-6363ab12964d","_uuid":"70ba7b9f-bbfd-44ed-8620-976e97ae2c8b","id":"TuaAoPQU4qNu","trusted":true},"source":["If we are on Kaggle we need to run the following cells to install Pytorch Geometric"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c6f4e319-9760-4147-a0cc-191f24b61b77","_uuid":"9646e447-62cf-4f23-a665-926e53a61479","collapsed":false,"id":"qhb60JfQ4qNu","jupyter":{"outputs_hidden":false},"outputId":"34d0c94b-4a2e-49fc-bcc6-fa20396710ed","trusted":true},"outputs":[],"source":["import torch\n","import os\n","\n","os.environ[\"TORCH\"] = torch.__version__\n","\n","# On Colab we can have TORCH+CUDA on os.environ[\"TORCH\"]\n","\n","# Check if there is the cuda version on TORCH\n","if torch.cuda.is_available():\n","    print(\"CUDA is available\")\n","    print(torch.version.cuda)\n","    if \"+\" not in os.environ[\"TORCH\"]:\n","        os.environ[\"TORCH\"] += \"+cu\" + \\\n","            torch.version.cuda.replace(\".\", \"\")\n","\n","print(os.environ[\"TORCH\"])"]},{"cell_type":"markdown","metadata":{},"source":["Install torch geometric and optional dependencies:"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"95a56f18-f34f-4aa7-9bbb-50f6663d0f2e","_uuid":"49338a06-0521-496f-a6f4-531d3d55ae04","collapsed":false,"id":"5xrzyr2i4qNw","jupyter":{"outputs_hidden":false},"outputId":"cec16773-237d-427a-d0bc-24bba40c85fa","scrolled":true,"trusted":true},"outputs":[],"source":["# ! pip install torch_geometric\n","# Optional dependencies:\n","# # ! pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\n","# # ! pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n","# ! pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-${TORCH}.html"]},{"cell_type":"markdown","metadata":{},"source":["or"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b62b5888-066b-4194-8078-82a7f35c2c61","_uuid":"3353b294-3bc7-43fa-ab04-b7e52ff4bfe6","collapsed":false,"execution":{"iopub.execute_input":"2023-09-07T14:16:40.976773Z","iopub.status.busy":"2023-09-07T14:16:40.976394Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2.0.0\n"]}],"source":["# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n","# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n","# !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"]},{"cell_type":"markdown","metadata":{},"source":["Install Graph Library:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Graph\n","! pip install igraph\n","! pip install cdlib[C]"]},{"cell_type":"markdown","metadata":{"_cell_guid":"6c434269-bbe5-471e-9837-32eb4797b632","_uuid":"96df44d7-6753-48a0-bdfa-f064dcfc38a8","id":"ax8CbJZsgSsW","trusted":true},"source":["**IMPORTANT!!!**\n","After the libraries installation, restart the runtime and start executing the cells below"]},{"cell_type":"markdown","metadata":{"_cell_guid":"75539a6d-e94f-44dd-b140-54371e7c6bc4","_uuid":"fe95edcb-9a91-483a-9fde-a986591481b9","id":"z5ImUEyx4qNx","trusted":true},"source":["## Import Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"11654998-cc12-44b6-be88-72bc30a27d72","_uuid":"bf86a857-762d-473f-ac47-b214ce5ca0c9","collapsed":false,"execution":{"iopub.execute_input":"2023-09-07T14:16:23.695334Z","iopub.status.busy":"2023-09-07T14:16:23.694910Z","iopub.status.idle":"2023-09-07T14:16:25.894248Z","shell.execute_reply":"2023-09-07T14:16:25.892177Z","shell.execute_reply.started":"2023-09-07T14:16:23.695298Z"},"id":"39avPlWH4qNx","jupyter":{"outputs_hidden":false},"outputId":"78bbb054-094e-4685-91a7-bc2305b21243","trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'torch_geometric'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter, namedtuple\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Deep Learning\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_networkx\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Batch\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'"]}],"source":["# Import torch and os another time to reset the colab enviroment after PyG installation\n","import torch\n","import os\n","import gc\n","\n","# Typing\n","from typing import List, Tuple, Set\n","from collections import Counter, namedtuple\n","\n","# Deep Learning\n","from torch_geometric.utils import from_networkx\n","from torch_geometric.data import Data\n","from torch_geometric.data import Batch\n","from torch_geometric.nn import GCNConv, GATConv\n","from torch_geometric.nn import global_mean_pool\n","from torch.distributions import MultivariateNormal\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import scipy\n","\n","# Graph\n","from cdlib import algorithms\n","import cdlib\n","import networkx as nx\n","import igraph as ig\n","\n","\n","# Misc\n","from enum import Enum\n","from tqdm import trange\n","import math\n","import random\n","import json\n","\n","# Plot\n","import matplotlib.pyplot as plt\n","plt.style.use('default')"]},{"cell_type":"markdown","metadata":{"_cell_guid":"5e1042f3-4d76-4247-be62-b76938b0a84b","_uuid":"aa35c47a-e038-4d07-a98c-8b122c860ccf","id":"5VGevrvC4qNy","trusted":true},"source":["## Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"21216b4a-7ec5-4f03-9eef-3d1b962e1f7d","_uuid":"2128c3d4-dbf0-4b52-81d1-d9490ba9cf56","collapsed":false,"execution":{"iopub.status.busy":"2023-09-07T14:16:25.895385Z","iopub.status.idle":"2023-09-07T14:16:25.895776Z","shell.execute_reply":"2023-09-07T14:16:25.895612Z","shell.execute_reply.started":"2023-09-07T14:16:25.895593Z"},"id":"Pairxi9g4qNy","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class FilePaths(Enum):\n","    \"\"\"Class to store file paths for data and models\"\"\"\n","    # ° Local\n","    # DATASETS_DIR = 'dataset/data'\n","    # LOG_DIR    = 'src/logs/'\n","    # TEST_DIR = 'test/'\n","    # ° Kaggle\n","    # DATASETS_DIR = '/kaggle/input/network-community'\n","    # LOG_DIR = '/kaggle/working/logs/'\n","    # TEST_DIR = '/kaggle/working/test/'\n","    # ° Google Colab\n","    DATASETS_DIR = \"/content/drive/MyDrive/Sapienza/Tesi/Datasets\"\n","    LOG_DIR = \"/content/drive/MyDrive/Sapienza/Tesi/Logs/\"\n","    TEST_DIR = \"/content/drive/MyDrive/Sapienza/Tesi/Test/\n","    \n","    # Dataset file paths\n","    KAR = DATASETS_DIR + '/kar.mtx'\n","    DOL = DATASETS_DIR + '/dol.mtx'\n","    MAD = DATASETS_DIR + '/mad.mtx'\n","    LESM = DATASETS_DIR + '/lesm.mtx'\n","    POLB = DATASETS_DIR + '/polb.mtx'\n","    WORDS = DATASETS_DIR + '/words.mtx'\n","    ERDOS = DATASETS_DIR + '/erdos.mtx'\n","    POW = DATASETS_DIR + '/pow.mtx'\n","    FB_75 = DATASETS_DIR + '/fb-75.mtx'\n","    DBLP = DATASETS_DIR + '/dblp.mtx'\n","    ASTR = DATASETS_DIR + '/astr.mtx'\n","    AMZ = DATASETS_DIR + '/amz.mtx'\n","    YOU = DATASETS_DIR + '/you.mtx'\n","    ORK = DATASETS_DIR + '/ork.mtx'\n","\n","\n","class HyperParams(Enum):\n","    \"\"\"Hyperparameters for the Environment\"\"\"\n","    # Numeber of possible action with BETA=30, is 30% of the edges\n","    BETA = 10  \n","    # Weight to balance the reward\n","    WEIGHT = 0.1  # 0.001, 0.01, 0.1, 1, 10\n","    \n","    \"\"\" Graph Encoder Parameters \"\"\"\"\"\n","    STATE_DIM = 64\n","    # G_HIDDEN_SIZE_1 = 128\n","    # G_HIDDEN_SIZE_2 = 64\n","    # G_EMBEDDING_SIZE = 32\n","\n","    \"\"\" Agent Parameters\"\"\"\n","    HIDDEN_SIZE_1 = 32\n","    HIDDEN_SIZE_2 = 32\n","    ACTION_DIM = 1      # We will return a  N*1 vector of actions, where N is the number of nodes\n","    # ACTION_STD = 0.5\n","    EPS_CLIP = np.finfo(np.float32).eps.item()  # 0.2\n","    LR = 0.0001\n","    GAMMA = 0.5 # 0.97\n","    BEST_REWARD = 0.7  # -np.inf\n","\n","    \"\"\" Training Parameters \"\"\"\n","    # Number of episodes to collect experience\n","    MAX_EPISODES = 1000  # 200 # 15000\n","    # Dictonary for logging\n","    LOG_DICT = {\n","        'train_reward': [],\n","        # Number of steps per episode\n","        'train_steps': [],\n","        # Average reward per step\n","        'train_avg_reward': [],\n","        # Average Actor loss per episode\n","        'a_loss': [],\n","        # Average Critic loss per episode\n","        'v_loss': [],\n","        # set max number of training episodes\n","        'train_episodes': MAX_EPISODES,\n","    }\n","    \n","    \"\"\"Graph Generation Parameters\"\"\"\n","    N_NODE = 10000\n","    TAU1 = 3\n","    TAU2 = 1.5\n","    MU = 0.1             # TODO: Test also 0.3 and 0.6\n","    AVERAGE_DEGREE = 5\n","    MIN_COMMUNITY = 20\n","    SEED= 10\n","\n","    \"\"\"Old Training Parameters\"\"\"\n","    # Maximum number of time steps per episode\n","    # MAX_TIMESTEPS = 10  # ! Unused, I set it to the double of the edge budget\n","    # Update the policy after N timesteps\n","    # UPDATE_TIMESTEP = 100  # ! Unused, I set it to 10 times the edge budget\n","    # Update policy for K epochs\n","    # K_EPOCHS = 20\n","    # Print info about the model after N episodes\n","    # LOG_INTERVAL = 20\n","    # Exit if the average reward is greater than this value\n","    # SOLVED_REWARD = 0.7\n","    # Save model after N episodes\n","    # SAVE_MODEL = int(MAX_EPISODES / 10)\n","    # Use a random seed\n","    # RANDOM_SEED = 42\n","\n","\n","class DetectionAlgorithms(Enum):\n","    \"\"\"\n","    Enum class for the detection algorithms\n","    \"\"\"\n","    LOUV = \"louvain\"\n","    WALK = \"walktrap\"\n","    GRE = \"greedy\"\n","    INF = \"infomap\"\n","    LAB = \"label_propagation\"\n","    EIG = \"eigenvector\"\n","    BTW = \"edge_betweenness\"\n","    SPIN = \"spinglass\"\n","    OPT = \"optimal\"\n","    SCD = \"scalable_community_detection\"\n","\n","\n","class Utils:\n","    \"\"\"Class to store utility functions\"\"\"\n","\n","    @staticmethod\n","    def import_mtx_graph(file_path: str) -> nx.Graph:\n","        \"\"\"\n","        Import a graph from a .mtx file\n","\n","        Parameters\n","        ----------\n","        file_path : str\n","            File path of the .mtx file\n","\n","        Returns\n","        -------\n","        nx.Graph\n","            Graph imported from the .mtx file\n","        \"\"\"\n","        try:\n","            graph_matrix = scipy.io.mmread(file_path)\n","            graph = nx.Graph(graph_matrix)\n","            for node in graph.nodes:\n","                # graph.nodes[node]['name'] = node\n","                graph.nodes[node]['num_neighbors'] = len(\n","                    list(graph.neighbors(node)))\n","            return graph\n","        except Exception as exception:\n","            print(\"Error: \", exception)\n","            return None\n","    \n","    @staticmethod\n","    def generate_lfr_benchmark_graph(\n","        n: int=HyperParams.N_NODE.value,\n","        tau1: float=HyperParams.TAU1.value,\n","        tau2: float=HyperParams.TAU2.value,\n","        mu: float=HyperParams.MU.value,              \n","        average_degree: float=HyperParams.AVERAGE_DEGREE.value, \n","        min_community: int=HyperParams.MIN_COMMUNITY.value, \n","        seed: int=HyperParams.SEED.value)->Tuple[nx.Graph, str]:\n","        \"\"\"\n","        Generate a LFR benchmark graph for community detection algorithms.\n","\n","        Parameters\n","        ----------\n","        n : int, optional\n","            _description_, by default 250\n","        tau1 : float, optional\n","            _description_, by default 3\n","        tau2 : float, optional\n","            _description_, by default 1.5\n","        mu : float, optional\n","            _description_, by default 0.1\n","        average_degree : float, optional\n","            _description_, by default 5\n","        min_community : int, optional\n","            _description_, by default 20\n","        seed : int, optional\n","            _description_, by default 10\n","\n","        Returns\n","        -------\n","        nx.Graph\n","            Synthetic graph generated with the LFR benchmark\n","        file_path : str\n","            Path to the file where the graph is saved\n","        \"\"\"\n","        graph = nx.generators.community.LFR_benchmark_graph(\n","            n=n,\n","            tau1=tau1,\n","            tau2=tau2,\n","            mu=mu,\n","            average_degree=average_degree,\n","            min_community=min_community,\n","            seed=seed)\n","        file_path = FilePaths.DATASETS_DIR.value + f\"/lfr_benchmark_mu-{mu}.mtx\"\n","        nx.write_edgelist(graph, file_path, data=False)\n","        # Delete community attribute from the nodes to handle PyG compatibility\n","        for node in graph.nodes:\n","            if 'community' in graph.nodes[node]:\n","                del graph.nodes[node]['community']\n","        for edge in graph.edges:\n","            graph.edges[edge]['weight'] = 1\n","        return graph, file_path\n","        \n","    @staticmethod\n","    def check_dir(path: str):\n","        \"\"\"\n","        Check if the directory exists, if not create it.\n","\n","        Parameters\n","        ----------\n","        path : str\n","            Path to the directory\n","        \"\"\"\n","        if not os.path.exists(path):\n","            os.makedirs(path)\n","    \n","    @staticmethod\n","    def plot_training(\n","        log: dict, \n","        env_name: str, \n","        detection_algorithm: str,\n","        file_path: str,\n","        window_size: int=100):\n","        \"\"\"Plot the training results\n","\n","        Parameters\n","        ----------\n","        log : dict\n","            Dictionary containing the training logs\n","        env_name : str\n","            Name of the environment\n","        detection_algorithm : str\n","            Name of the detection algorithm\n","        file_path : str\n","            Path to save the plot\n","        window_size : int, optional\n","            Size of the rolling window, by default 100\n","        \"\"\"\n","        def plot_time_series(\n","            list_1: List[float],\n","            list_2: List[float],\n","            label_1: str,\n","            label_2: str,\n","            color_1: str,\n","            color_2: str,\n","            file_name: str):\n","            _, ax1 = plt.subplots()\n","            color = 'tab:'+color_1\n","            ax1.set_xlabel(\"Episode\")\n","            ax1.set_ylabel(label_1, color=color)\n","            ax1.plot(list_1, color=color)\n","            ax1.tick_params(axis='y', labelcolor=color)\n","\n","            ax2 = ax1.twinx()\n","            color = 'tab:'+color_2\n","            ax2.set_ylabel(label_2, color=color)\n","            ax2.plot(list_2, color=color)\n","            ax2.tick_params(axis='y', labelcolor=color)\n","\n","            plt.title(\n","                f\"Training on {env_name} graph with {detection_algorithm} algorithm\")\n","            plt.savefig(file_name)\n","            plt.show()\n","        \n","        def plot_rolling_window(\n","            list_1: List[float],\n","            list_2: List[float],\n","            label_1: str,\n","            label_2: str,\n","            file_name: str,\n","            window_size: int = 100):\n","            time_series_1 = np.array(list_1)\n","            time_series_2 = np.array(list_2)\n","            # Compute the rolling windows of the time series data using NumPy\n","            rolling_data_1 = np.convolve(time_series_1, np.ones(\n","                window_size) / window_size, mode='valid')\n","            rolling_data_2 = np.convolve(time_series_2, np.ones(\n","                window_size) / window_size, mode='valid')\n","            # Plot the rolling windows of the time series data using matplotlib\n","            plt.plot(rolling_data_1, label=label_1)\n","            plt.plot(rolling_data_2, label=label_2)\n","            plt.title(\"Rolling Window\")\n","            plt.xlabel(\"Epochs\")\n","            # plt.ylabel(\"Epochs\")\n","            plt.legend()\n","            plt.savefig(file_name)\n","            plt.show()\n","        \n","        file_path = file_path+\"/\"+env_name+\"_\"+detection_algorithm\n","        plot_time_series(\n","            log['train_avg_reward'],\n","            log['train_steps'],\n","            'Avg Reward',\n","            'Steps per Epoch',\n","            'blue',\n","            'orange',\n","            file_path+\"_training_reward.png\",\n","        )\n","        plot_time_series(\n","            log[\"a_loss\"],\n","            log[\"v_loss\"],\n","            'Actor Loss',\n","            'Critic Loss',\n","            'green',\n","            'red',\n","            file_path+\"_training_loss.png\",\n","        )\n","\n","        # Same plot with rolling window\n","        plot_rolling_window(\n","            log['train_reward'], \n","            log['train_steps'], \n","            'Avg Reward', \n","            'Steps per Epoch',\n","            file_path+\"_rolling_training_reward.png\"\n","        )\n","        plot_rolling_window(\n","            log[\"a_loss\"],\n","            log[\"v_loss\"],\n","            'Actor Loss',\n","            'Critic Loss',\n","            file_path+\"_rolling_training_loss.png\"\n","        )\n","    \n","    @staticmethod\n","    def save_training(\n","            log: dict,\n","            env_name: str,\n","            detection_algorithm: str,\n","            file_path: str):\n","        \"\"\"Plot the training results\n","\n","        Parameters\n","        ----------\n","        log : dict\n","            Dictionary containing the training logs\n","        env_name : str\n","            Name of the environment\n","        detection_algorithm : str\n","            Name of the detection algorithm\n","        file_path : str\n","            Path to save the plot\n","        \"\"\"\n","        file_name = f\"{file_path}/{env_name}_{detection_algorithm}_results.json\"\n","        with open(file_name, \"w\", encoding=\"utf-8\") as f:\n","            json.dump(log, f, indent=4)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4b08c13f-6d30-4fd3-9db7-d473f48a7962","_uuid":"f6c177fe-444c-4d7a-8bd3-b426f3306d2e","collapsed":false,"execution":{"iopub.status.busy":"2023-09-07T14:16:25.899844Z","iopub.status.idle":"2023-09-07T14:16:25.900706Z","shell.execute_reply":"2023-09-07T14:16:25.900482Z","shell.execute_reply.started":"2023-09-07T14:16:25.900458Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# Create paths\n","Utils.check_dir(FilePaths.LOG_DIR.value)\n","Utils.check_dir(FilePaths.TEST_DIR.value)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"18777a8c-0ec0-47fd-be6f-bad8d2620d07","_uuid":"2964b49a-91f3-4d99-a1c8-0950e9e9b53b","id":"iJUWAWt24qNz","trusted":true},"source":["## Community Algorithms"]},{"cell_type":"markdown","metadata":{"_cell_guid":"4beefafe-d5c8-47bc-aa75-8c94fb41296c","_uuid":"81e8e2e1-7c7a-4c32-9d0d-07ce21120d0b","id":"ctdHdmia4qN0","trusted":true},"source":["### Communities Detection"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5ea2d660-1f91-4c56-8897-62ae44700433","_uuid":"a1364c7a-cfc3-4bca-b39b-b117898a0a1c","collapsed":false,"execution":{"iopub.status.busy":"2023-09-07T14:16:25.902272Z","iopub.status.idle":"2023-09-07T14:16:25.902991Z","shell.execute_reply":"2023-09-07T14:16:25.902774Z","shell.execute_reply.started":"2023-09-07T14:16:25.902750Z"},"id":"lXOSaaPJ4qN0","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class CommunityDetectionAlgorithm(object):\n","    \"\"\"Class for the community detection algorithms using CDLIB\"\"\"\n","    def __init__(self, alg_name: str) -> None:\n","        \"\"\"\n","        Initialize the DetectionAlgorithm object\n","        \n","        Parameters\n","        ----------\n","        alg_name : str\n","            The name of the algorithm\n","        \"\"\"\n","        self.alg_name = alg_name\n","    \n","    def compute_community(self, graph: nx.Graph) -> cdlib.NodeClustering:\n","        \"\"\"Compute the community partition of the graph\n","\n","        Parameters\n","        ----------\n","        graph : nx.Graph\n","            Input graph\n","\n","        Returns\n","        -------\n","        cdlib.NodeClustering\n","            Cdlib NodeClustering object\n","        \"\"\"\n","        # Rename DetectionAlgorithms Enum to da for convenience\n","        da = DetectionAlgorithms\n","        # Choose the algorithm\n","        if self.alg_name == da.LOUV.value:\n","            return algorithms.louvain(graph)\n","        elif self.alg_name == da.WALK.value:\n","            return algorithms.walktrap(graph)\n","        elif self.alg_name == da.GRE.value:\n","            return algorithms.greedy_modularity(graph)\n","        elif self.alg_name == da.INF.value:\n","            return algorithms.infomap(graph)\n","        # elif self.alg_name == da.LAB.value:\n","        #    # ! Return a EdgeClustering object\n","        #    return algorithms.label_propagation(graph)\n","        elif self.alg_name == da.EIG.value:\n","            return algorithms.eigenvector(graph)\n","        # elif self.alg_name == da.BTW.value:\n","        #     return self.compute_btw(graph, args)\n","        elif self.alg_name == da.SPIN.value:\n","            return algorithms.spinglass(graph)\n","        # elif self.alg_name == da.OPT.value:\n","        #    return self.compute_opt(graph, args)\n","        # elif self.alg_name == da.SCD.value:\n","        #    return self.compute_scd(graph)\n","        else:\n","            raise ValueError('Invalid algorithm name')"]},{"cell_type":"markdown","metadata":{"_cell_guid":"75e5dee8-febd-4923-8d2b-70f0694f940d","_uuid":"0d92f0e4-3d10-450a-a144-74dd990dc4c2","id":"Wg5dgtUo4qN1","trusted":true},"source":["### Normalized Mutual Information Score"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2f14358d-b690-41d3-b61c-7704015bbf8b","_uuid":"2e10236c-18cd-4b0c-86fe-478fb1b3d153","collapsed":false,"execution":{"iopub.status.busy":"2023-09-07T14:16:25.904443Z","iopub.status.idle":"2023-09-07T14:16:25.905186Z","shell.execute_reply":"2023-09-07T14:16:25.904954Z","shell.execute_reply.started":"2023-09-07T14:16:25.904931Z"},"id":"-UVHWawt4qN2","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["\n","class NormalizedMutualInformation(object):\n","    @staticmethod\n","    def calculate_confusion_matrix(\n","            communities_old: List[List[int]],\n","            communities_new: List[List[int]]) -> Counter:\n","        \"\"\"\n","        Calculate the confusion matrix between two sets of communities.\n","        Where the element (i, j) of the confusion matrix is the number of shared\n","        members between an initially detected community C_i and the community\n","        C_j after deception.\n","\n","        Parameters\n","        ----------\n","        communities_old : List[List[int]]\n","            Communities before deception\n","        communities_new : List[List[int]]\n","            Communities after deception\n","\n","        Returns\n","        -------\n","        confusion_matrix : Counter\n","            Confusion matrix\n","        \"\"\"\n","        confusion_matrix = Counter()\n","        #° Avoid to process the same community twice\n","        #BUG ZeroDivisionError if we use this optimization\n","        #BUG processed_new = set()\n","        for i, old in enumerate(communities_old):\n","            for j, new in enumerate(communities_new):\n","                #BUG if j not in processed_new:\n","                intersection = len(set(old) & set(new))\n","                confusion_matrix[(i, j)] = intersection\n","                #BUG    if intersection > 0:\n","                #BUG        processed_new.add(j)\n","        return confusion_matrix\n","\n","    @staticmethod\n","    def calculate_sums(confusion_matrix: Counter) -> Tuple[Counter, Counter, int]:\n","        \"\"\"\n","        Calculate the row sums, column sums and total sum of a confusion matrix.\n","\n","        Parameters\n","        ----------\n","        confusion_matrix : Counter\n","            Confusion matrix\n","\n","        Returns\n","        -------\n","        (row_sums, col_sums, total_sum) : Tuple[Counter, Counter, int]\n","            Tuple containing the row sums, column sums and total sum of the\n","            confusion matrix.\n","        \"\"\"\n","        row_sums = Counter()\n","        col_sums = Counter()\n","        total_sum = 0\n","        for (i, j), value in confusion_matrix.items():\n","            row_sums[i] += value\n","            col_sums[j] += value\n","            total_sum += value\n","        return row_sums, col_sums, total_sum\n","\n","    def compute_nmi(\n","            self,\n","            communities_old: List[List[int]],\n","            communities_new: List[List[int]]) -> float:\n","        \"\"\"\n","        Calculate the normalized mutual information between two sets of\n","        Communities.\n","\n","        Parameters\n","        ----------\n","        communities_old : List[List[int]]\n","            List of communities before deception\n","        communities_new : List[List[int]]\n","            List of communities after deception\n","\n","        Returns\n","        -------\n","        nmi : float\n","            Normalized mutual information, value between 0 and 1.\n","        \"\"\"\n","        confusion_matrix = self.calculate_confusion_matrix(\n","            communities_old, communities_new)\n","        row_sums, col_sums, total_sum = self.calculate_sums(confusion_matrix)\n","\n","        # Numerator\n","        nmi_numerator = 0\n","        for (i, j), n_ij in confusion_matrix.items():\n","            n_i = row_sums[i]\n","            n_j = col_sums[j]\n","            try:\n","                nmi_numerator += n_ij * math.log((n_ij * total_sum) / (n_i * n_j))\n","            except ValueError:\n","                # We could get a math domain error if n_ij is 0\n","                continue\n","\n","        # Denominator\n","        nmi_denominator = 0\n","        for i, n_i in row_sums.items():\n","            nmi_denominator += n_i * math.log(n_i / total_sum)\n","        for j, n_j in col_sums.items():\n","            nmi_denominator += n_j * math.log(n_j / total_sum)\n","        # Normalized mutual information\n","        nmi_score = -2 * nmi_numerator / nmi_denominator\n","        return nmi_score"]},{"cell_type":"markdown","metadata":{"_cell_guid":"ceeaedf8-6720-420a-b65e-d06a50c808b6","_uuid":"4c7613d9-d95e-4eb0-b9d1-8d95928c459f","id":"-l6FamFa4qN2","trusted":true},"source":["## Enviroment"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"1fdc6a76-c3f9-4504-876f-1764509417cd","_uuid":"3ebe6bed-0762-40d3-bbab-e47dcb6e671f","collapsed":false,"execution":{"iopub.execute_input":"2023-09-07T14:16:26.241589Z","iopub.status.busy":"2023-09-07T14:16:26.241171Z","iopub.status.idle":"2023-09-07T14:16:26.509240Z","shell.execute_reply":"2023-09-07T14:16:26.507071Z","shell.execute_reply.started":"2023-09-07T14:16:26.241547Z"},"id":"iQDrQKvy4qN2","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'HyperParams' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGraphEnvironment\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Enviroment where the agent will act, it will be a graph with a community\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m      6\u001b[0m         graph: nx\u001b[38;5;241m.\u001b[39mGraph, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m         beta: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m HyperParams\u001b[38;5;241m.\u001b[39mBETA\u001b[38;5;241m.\u001b[39mvalue, \n\u001b[1;32m     13\u001b[0m         weight: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m HyperParams\u001b[38;5;241m.\u001b[39mWEIGHT\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n","Cell \u001b[0;32mIn[2], line 12\u001b[0m, in \u001b[0;36mGraphEnvironment\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGraphEnvironment\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Enviroment where the agent will act, it will be a graph with a community\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m      6\u001b[0m         graph: nx\u001b[38;5;241m.\u001b[39mGraph, \n\u001b[1;32m      7\u001b[0m         community: List[\u001b[38;5;28mint\u001b[39m], \n\u001b[1;32m      8\u001b[0m         idx_community: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m      9\u001b[0m         node_target: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m     10\u001b[0m         env_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     11\u001b[0m         community_detection_algorithm: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m---> 12\u001b[0m         beta: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mHyperParams\u001b[49m\u001b[38;5;241m.\u001b[39mBETA\u001b[38;5;241m.\u001b[39mvalue, \n\u001b[1;32m     13\u001b[0m         weight: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m HyperParams\u001b[38;5;241m.\u001b[39mWEIGHT\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"Constructor for Graph Environment\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m        Parameters\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m        ----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m            Weight of the metric, by default HyperParams.WEIGHT.value\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;241m=\u001b[39m graph\n","\u001b[0;31mNameError\u001b[0m: name 'HyperParams' is not defined"]}],"source":["class GraphEnvironment(object):\n","    \"\"\"Enviroment where the agent will act, it will be a graph with a community\"\"\"\n","\n","    def __init__(\n","        self, \n","        graph: nx.Graph, \n","        community: List[int], \n","        idx_community: int,\n","        node_target: int,\n","        env_name: str,\n","        community_detection_algorithm: str,\n","        beta: float = HyperParams.BETA.value, \n","        weight: float = HyperParams.WEIGHT.value) -> None:\n","        \"\"\"Constructor for Graph Environment\n","        Parameters\n","        ----------\n","        graph : nx.Graph\n","            Graph to use for the environment\n","        community : List[int]\n","            Community of node we want to remove from it\n","        idx_community : int\n","            Index of the community in the list of communities\n","        nodes_target : int\n","            Node we want to remove from the community\n","        env_name : str\n","            Name of the environment, i.e. name of the dataset\n","        community_detection_algorithm : str\n","            Name of the community detection algorithm to use\n","        beta : float, optional\n","            Percentage of edges to remove, by default HyperParams.BETA.value\n","        weight : float, optional\n","            Weight of the metric, by default HyperParams.WEIGHT.value\n","        \"\"\"\n","        self.graph = graph\n","        self.graph_copy = graph.copy()\n","        # Get the Number of connected components\n","        self.n_connected_components = nx.number_connected_components(graph)\n","        \n","        # Community to hide\n","        self.community_target = community\n","        self.idx_community_target = idx_community\n","        \n","        # Node to remove from the community\n","        assert node_target in community, \"Node must be in the community\"\n","        self.node_target = node_target\n","        \n","        assert beta >= 0 and beta <= 100, \"Beta must be between 0 and 100\"\n","        self.beta = beta\n","        self.weight = weight\n","        self.env_name = env_name\n","        \n","        # Community Algorithms objects\n","        self.detection = CommunityDetectionAlgorithm(community_detection_algorithm)\n","        self.deception = DeceptionScore(self.community_target)\n","        # self.safeness = Safeness(self.graph, self.community_target, self.node_target)\n","        self.nmi = NormalizedMutualInformation()\n","        # Compute the community structure of the graph, before the action,\n","        # i.e. before the deception\n","        self.community_structure_start = self.detection.compute_community(graph)\n","        # ! It is a NodeClustering object\n","        self.community_structure_old = self.community_structure_start\n","        \n","        # Compute the edge budget for the graph\n","        self.edge_budget = self.get_edge_budget()\n","        # Amount of budget used\n","        self.used_edge_budget = 0\n","        # Whether the budget for the graph rewiring is exhausted, or the target\n","        # node does not belong to the community anymore\n","        self.stop_episode = False\n","        self.rewards = 0\n","        # Reward of the previous step\n","        self.old_rewards = 0\n","        \n","        # Compute the set of possible actions\n","        self.possible_actions = self.get_possible_actions()\n","        # Length of the list of possible actions to add\n","        self.len_add_actions = len(self.possible_actions[\"ADD\"])\n","        \n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    def change_target_node(self, node_target: int=None) -> None:\n","        \"\"\"\n","        Change the target node to remove from the community\n","\n","        Parameters\n","        ----------\n","        node_target : int, optional\n","            Node to remove from the community, by default None\n","        \"\"\"\n","        if node_target is None:\n","            # Choose a node randomly from the community\n","            idx_node = random.randint(0, len(self.community_target)-1)\n","            self.node_target = self.community_target[idx_node]\n","        else:\n","            self.node_target = node_target\n","    \n","    def change_target_community(\n","        self, \n","        community: List[int]=None, \n","        idx_community: int=None,\n","        node_target: int=None) -> None:\n","        \"\"\"\n","        Change the target community from which we want to hide the node\n","\n","        Parameters\n","        ----------\n","        community : List[int]\n","            Community of node we want to remove from it\n","        idx_community : int\n","            Index of the community in the list of communities\n","        \"\"\"\n","        if community is None:\n","            # Choose a community randomly from the list of communities\n","            self.idx_community_target = random.randint(\n","                0, len(self.community_structure_start.communities)-1)\n","            self.community_target = self.community_structure_start.communities[\n","                self.idx_community_target]\n","        else:\n","            self.community_target = community\n","            self.idx_community_target = idx_community\n","        self.change_target_node(node_target=node_target)\n","    \n","    def get_community_target_idx(\n","        self,\n","        community_structure: List[List[int]],\n","        community_target: List[int]) -> int:\n","        \"\"\"\n","        Returns the index of the target community in the list of communities\n","        As the target community after a rewiring action we consider the community\n","        with the highest number of nodes equal to the initial community.\n","        \n","        Parameters\n","        ----------\n","        community_structure : List[List[int]]\n","            List of communities\n","        community_target : List[int]\n","            Community of node we want to remove from it\n","        \n","        Returns\n","        -------\n","        max_list_idx : int\n","            Index of the target community in the list of communities\n","        \"\"\"\n","        max_count = 0\n","        max_list_idx = 0\n","        for i, lst in enumerate(community_structure):\n","            count = sum(1 for x in lst if x in community_target)\n","            if count > max_count:\n","                max_count = count\n","                max_list_idx = i\n","        return max_list_idx\n","    \n","    def get_edge_budget(self) -> int:\n","        \"\"\"\n","        Computes the edge budget for each graph\n","\n","        Returns\n","        -------\n","        int\n","            Edge budgets of the graph\n","        \"\"\"\n","        return int(math.ceil((self.graph.number_of_edges() * self.beta / 100)))\n","\n","    def get_reward(self, metric: float) -> Tuple[float, bool]:\n","        \"\"\"\n","        Computes the reward for the agent\n","        \n","        Parameters\n","        ----------\n","        metric : float\n","            Metric to use to compute the reward\n","\n","        Returns\n","        -------\n","        reward : float\n","            Reward of the agent\n","        done : bool\n","            Whether the episode is finished, if the target node does not belong\n","            to the community anymore, the episode is finished\n","        \"\"\"\n","        # if the target node still belongs to the community, the reward is negative \n","        communities_list = self.community_structure_new.communities\n","        if self.node_target in communities_list[self.idx_community_target]:\n","            reward = -self.weight * metric\n","            return reward, False\n","        # if the target node does not belong to the community anymore, the reward is positive\n","        reward = 1 - (self.weight * metric)\n","        return reward, True\n","\n","    def reset(self) -> Data:\n","        \"\"\"\n","        Reset the environment\n","\n","        Returns\n","        -------\n","        adj_matrix : torch.Tensor\n","            Adjacency matrix of the graph\n","        \"\"\"\n","        self.used_edge_budget = 0\n","        self.stop_episode = False\n","        self.graph = self.graph_copy.copy()\n","        self.possible_actions = self.get_possible_actions()\n","        \n","        # Return a PyG Data object\n","        self.data_pyg = from_networkx(self.graph)\n","        # Initialize the node features\n","        self.data_pyg.x = torch.randn([self.data_pyg.num_nodes, HyperParams.G_IN_SIZE.value])\n","        # Initialize the batch\n","        self.data_pyg.batch = torch.zeros(self.data_pyg.num_nodes).long()\n","        return self.data_pyg.to(self.device)\n","    \n","    def step(self, action: int) -> Tuple[Data, float]:\n","        \"\"\"\n","        Step function for the environment\n","        \n","        Parameters\n","        ----------\n","        action : int\n","            Integer representing a node in the graph, it will be the destination\n","            node of the rewiring action (out source node is always the target node).\n","            \n","        Returns\n","        -------\n","        self.graph, self.rewards: Tuple[torch.Tensor, float]\n","            Tuple containing the new graph and the reward \n","        \"\"\"\n","        # ° ---- ACTION ---- ° #\n","        # Take action, budget_consumed can be 0 or 1, i.e. if the action has\n","        # been applied or not\n","        budget_consumed = self.apply_action(action)\n","        # Set a negative reward if the action has not been applied\n","        if budget_consumed == 0:\n","            self.rewards = -2\n","            # The state is the same as before\n","            return self.data_pyg.to(self.device), self.rewards, self.stop_episode\n","        \n","        # ° ---- METRICS ---- ° #\n","        # Compute the new Community Structure after the action\n","        self.community_structure_new = self.detection.compute_community(self.graph)\n","        # Search the index of the target community in the new list of communities\n","        self.idx_community_target = self.get_community_target_idx(\n","            self.community_structure_new.communities, \n","            self.community_target)\n","        \n","        # ! It is a NodeClustering object\n","        # nmi = self.community_structure_new.normalized_mutual_information(\n","        #    self.community_structure_old).score\n","        # NOTE: My implementation of NMI is faster than the one in cdlib\n","        # Normalized Mutual Information, value between 0 and 1\n","        nmi = self.nmi.compute_nmi(\n","            self.community_structure_old.communities, \n","            self.community_structure_new.communities)\n","        \n","        # Deception Score, value between 0 and 1\n","        # deception_score = self.deception.compute_deception_score(self.community_structure_new.communities, self.n_connected_components)\n","        # Safeness, value between 0 and 1\n","        # node_safeness = self.safeness.compute_community_safeness(self.nodes_target)\n","        # node_safeness = self.safeness.compute_node_safeness(self.nodes_target[0]) # ! Assume that there is only one node to hide\n","        \n","        self.community_structure_old = self.community_structure_new\n","        \n","        # ° ---- REWARD ---- ° #\n","        self.rewards, done = self.get_reward(nmi)\n","        # If the target node does not belong to the community anymore, \n","        # the episode is finished\n","        if done:\n","            self.stop_episode = True\n","        \n","        # ° ---- BUDGET ---- ° #\n","        # Compute the remaining budget\n","        remaining_budget = self.edge_budget - self.used_edge_budget\n","        # Decrease the remaining budget\n","        updated_budget = remaining_budget - budget_consumed\n","        # Update the used edge budget\n","        self.used_edge_budget += (remaining_budget - updated_budget)\n","        # If the budget for the graph rewiring is exhausted, stop the episode\n","        if remaining_budget < 1:\n","            self.stop_episode = True\n","            # If the budget is exhausted, and the target node still belongs to\n","            # the community, the reward is negative\n","            if not done:\n","                self.rewards = -1\n","\n","        # ° ---- PyG Data ---- ° #\n","        # TEST: Avoid to use from_networkx\n","        edge_list = nx.to_edgelist(self.graph)\n","        # remove weights\n","        edge_list = [[e[0], e[1]] for e in edge_list]\n","        edge_list += [[e[1], e[0]] for e in edge_list]\n","        # order the list, first by first element, then by second element\n","        edge_list = sorted(edge_list, key=lambda x: (x[0], x[1]))\n","        # Create tensor\n","        edge_list = torch.tensor(edge_list)\n","        edge_list_t = torch.transpose(edge_list, 0, 1)\n","        del edge_list\n","        self.data_pyg.edge_index = edge_list_t\n","        # TEST END\n","        \n","        # Return a PyG Data object\n","        # TEST data = from_networkx(self.graph)\n","        # Assign the node features and the batch of the old graph to the new graph\n","        # TEST data.x = self.data_pyg.x\n","        # TEST data.batch = self.data_pyg.batch\n","        # Update the old graph pyg data object\n","        # TEST self.data_pyg = data\n","        return self.data_pyg.to(self.device), self.rewards, self.stop_episode\n","    \n","    def get_possible_actions(self) -> dict:\n","        \"\"\"\n","        Returns all the possible actions that can be applied to the graph\n","        given a source node (self.node_target). The possible actions are:\n","            - Add an edge between the source node and a node outside the community\n","            - Remove an edge between the source node and a node inside the community\n","        \n","        Returns\n","        -------\n","        self.possible_actions : dict\n","            Dictionary containing the possible actions that can be applied to\n","            the graph. The dictionary has two keys: \"ADD\" and \"REMOVE\", each\n","            key has a list of tuples as value, where each tuple is an action.\n","        \"\"\"\n","        possible_actions = {\"ADD\": set(), \"REMOVE\": set()}\n","        # Helper functions to check if a node is in/out-side the community\n","        def in_community(node):\n","            return node in self.community_target\n","\n","        def out_community(node):\n","            return node not in self.community_target\n","        \n","        u = self.node_target\n","        for v in self.graph.nodes():\n","            if u == v:\n","                continue\n","            # We can remove an edge iff both nodes are in the community\n","            if in_community(u) and in_community(v):\n","                if self.graph.has_edge(u, v):\n","                    if (v, u) not in possible_actions[\"REMOVE\"]:\n","                        possible_actions[\"REMOVE\"].add((u, v))\n","            # We can add an edge iff one node is in the community and the other is not\n","            elif (in_community(u) and out_community(v)) \\\n","                    or (out_community(u) and in_community(v)):\n","                # Check if there is already an edge between the two nodes\n","                if not self.graph.has_edge(u, v):\n","                    if (v, u) not in possible_actions[\"ADD\"]:\n","                        possible_actions[\"ADD\"].add((u, v))\n","        return possible_actions\n","    \n","    def apply_action(self, action: int) -> int:\n","        \"\"\"\n","        Applies the action to the graph, if there is an edge between the two \n","        nodes, it removes it, otherwise it adds it\n","\n","        Parameters\n","        ----------\n","        action : int\n","            Integer representing a node in the graph, it will be the destination\n","            node of the rewiring action (out source node is always the target node).\n","        \n","        Returns\n","        -------\n","        budget_consumed : int\n","            Amount of budget consumed, 1 if the action has been applied, 0 otherwise\n","        \"\"\"\n","        action = (self.node_target, action)   \n","        # We need to take into account both the actions (u,v) and (v,u)\n","        action_reversed = (action[1], action[0])\n","        if action in self.possible_actions[\"ADD\"]:\n","            self.graph.add_edge(*action, weight=1)\n","            self.possible_actions[\"ADD\"].remove(action)\n","            return 1\n","        elif action_reversed in self.possible_actions[\"ADD\"]:\n","            self.graph.add_edge(*action_reversed, weight=1)\n","            self.possible_actions[\"ADD\"].remove(action_reversed)\n","            return 1\n","        elif action in self.possible_actions[\"REMOVE\"]:\n","            self.graph.remove_edge(*action)\n","            self.possible_actions[\"REMOVE\"].remove(action)\n","            return 1\n","        elif action_reversed in self.possible_actions[\"REMOVE\"]:\n","            self.graph.remove_edge(*action_reversed)\n","            self.possible_actions[\"REMOVE\"].remove(action_reversed)\n","            return 1\n","        return 0\n","\n","    def plot_graph(self) -> None:\n","        \"\"\"Plot the graph using matplotlib\"\"\"\n","        import matplotlib.pyplot as plt\n","        nx.draw(self.graph, with_labels=True)\n","        plt.show()\n"]},{"cell_type":"markdown","metadata":{"_cell_guid":"f8573615-d7f2-4746-9a63-89c8f4f22b58","_uuid":"ffc24ac0-b9c6-4aca-9f60-df397d18451f","id":"vAdiThYJ4qN3","trusted":true},"source":["## Model"]},{"cell_type":"markdown","metadata":{"_cell_guid":"f5291eb5-7a23-44d5-8483-8839ec85b3e3","_uuid":"51f1dc83-1a52-4d46-9cc1-0351a7942fb9","id":"1JxHpEqT4qN3","trusted":true},"source":["### Encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b0f04523-a5ac-4e6e-a8ec-ffc73544de22","_uuid":"4700a845-4b44-4c60-b627-4455de2669f8","collapsed":false,"execution":{"iopub.status.busy":"2023-09-07T14:16:26.510414Z","iopub.status.idle":"2023-09-07T14:16:26.511590Z","shell.execute_reply":"2023-09-07T14:16:26.511356Z","shell.execute_reply.started":"2023-09-07T14:16:26.511331Z"},"id":"O5TwC47m4qN3","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class GraphEncoder(nn.Module):\n","    def __init__(\n","        self,\n","        in_feature, \n","        # embdedding_size,\n","        num_layers=2):\n","        super(GraphEncoder, self).__init__()\n","\n","        self.conv_layers = nn.ModuleList()\n","        # self.conv_layers.append(GCNConv(in_feature, in_feature))\n","        self.conv_layers.append(GATConv(in_feature, in_feature))\n","        for _ in range(num_layers - 1):\n","            # self.conv_layers.append(GCNConv(in_feature, in_feature))\n","            self.conv_layers.append(GATConv(in_feature, in_feature))\n","        \n","        self.relu = nn.LeakyReLU()\n","        #self.relu = nn.ReLU()\n","    \n","    #NOTE Torch Geometric MessagePassing, it takes as input the edge list \n","    def forward(self, graph: Data)-> torch.Tensor:\n","        x, edge_index, batch = graph.x, graph.edge_index, graph.batch\n","\n","        for conv in self.conv_layers:\n","            x = conv(x, edge_index)\n","            x = self.relu(x)\n","        # embedding = global_mean_pool(x, batch)\n","        # self.is_nan(x, \"x\")\n","        embedding = x + graph.x\n","        \n","        return embedding\n","\n","    def is_nan(self, x, label):\n","        \"\"\"Debugging function to check if there are NaN values in the tensor\"\"\"\n","        if torch.isnan(x).any():\n","            print(label, \":\", x)\n","            raise ValueError(label, \"is NaN\")\n"]},{"cell_type":"markdown","metadata":{"_cell_guid":"bdb2c8bd-ec95-4293-b9be-70ecfa9f3c1b","_uuid":"065700a9-c782-4a92-8abb-06cbb83acf28","id":"1S7ubGoY4qN4","trusted":true},"source":["### Network"]},{"cell_type":"markdown","metadata":{"_cell_guid":"c5de2a68-f7d0-4f19-9b0d-44279dbe451a","_uuid":"086c55ba-63e2-4ea2-8739-4b6e3827771a","id":"SfScUOtU4qN4","trusted":true},"source":["#### Actor"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"12372f56-95f9-4f14-b708-b925514768fb","_uuid":"ad385add-1ff5-49eb-96ae-35dfa1f62ebc","collapsed":false,"execution":{"iopub.status.busy":"2023-09-07T14:16:26.513266Z","iopub.status.idle":"2023-09-07T14:16:26.514188Z","shell.execute_reply":"2023-09-07T14:16:26.513932Z","shell.execute_reply.started":"2023-09-07T14:16:26.513908Z"},"id":"HV4Ef1504qN4","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class ActorNetwork(nn.Module):\n","    \"\"\"Actor Network\"\"\"\n","    \n","    def __init__(\n","            self,\n","            state_dim: int,\n","            hidden_size_1: int,\n","            hidden_size_2: int,\n","            action_dim: int):\n","        super(ActorNetwork, self).__init__()\n","        \n","        self.graph_encoder = GraphEncoder(state_dim)\n","        self.linear1 = nn.Linear(state_dim, hidden_size_1)\n","        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2)\n","        self.linear3 = nn.Linear(hidden_size_2, action_dim)\n","        \n","        self.relu = nn.LeakyReLU()\n","        # self.relu = nn.ReLU()\n","        # self.tanh = nn.Tanh()\n","\n","    def forward(self, state: Data):\n","        embedding = self.graph_encoder(state)\n","        actions = self.relu(self.linear1(embedding))\n","        actions = self.relu(self.linear2(actions))\n","        actions = self.linear3(actions)\n","        return actions\n","    \n","    def is_nan(self, x, label):\n","        \"\"\"Debugging function to check if there are NaN values in the tensor\"\"\"\n","        if torch.isnan(x).any():\n","            print(label, \":\", x)\n","            raise ValueError(label, \"is NaN\")"]},{"cell_type":"markdown","metadata":{"_cell_guid":"e2e118f7-d52d-4e73-997e-53a1a32afbe8","_uuid":"30ebc803-c985-4f23-95c4-3fc867216fde","id":"4L57IBdh4qN4","trusted":true},"source":["#### Critic"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"99f81ba0-98ed-4057-9476-259a0fd7f104","_uuid":"c10b6fa0-86d3-43fe-bfce-a7ef2ce8e457","collapsed":false,"execution":{"iopub.status.busy":"2023-09-07T14:16:26.515783Z","iopub.status.idle":"2023-09-07T14:16:26.516198Z","shell.execute_reply":"2023-09-07T14:16:26.516033Z","shell.execute_reply.started":"2023-09-07T14:16:26.516012Z"},"id":"jRxY8xcL4qN4","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class CriticNetwork(nn.Module):\n","    def __init__(\n","        self,\n","        state_dim: int,\n","        hidden_size_1: int,\n","        hidden_size_2: int):\n","        super(CriticNetwork, self).__init__()\n","        \n","        self.graph_encoder = GraphEncoder(state_dim)\n","        self.linear1 = nn.Linear(state_dim, hidden_size_1)\n","        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2)\n","        self.linear3 = nn.Linear(hidden_size_2, 1)\n","        \n","        self.relu = nn.LeakyReLU()\n","        # self.relu = nn.ReLU()\n","        # self.relu = F.relu\n","        # self.tanh = nn.Tanh()\n","\n","    def forward(self, state: Data):\n","        embedding = self.graph_encoder(state)\n","        embedding = torch.sum(embedding, dim=0)\n","        value = self.relu(self.linear1(embedding))\n","        value = self.relu(self.linear2(value))\n","        value = self.linear3(value)\n","        return value\n"]},{"cell_type":"markdown","metadata":{"_cell_guid":"c684e75b-3ab8-47b6-a8e9-c49277e517e4","_uuid":"85f6f4b9-3416-49ff-944e-e8fa0e040b51","id":"PJxe7FGi4qN5","trusted":true},"source":["#### A2C"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d46885ac-c16a-418f-a411-986b773b158b","_uuid":"7e035cf3-33ee-4920-a3ed-02b3c8104143","collapsed":false,"execution":{"iopub.status.busy":"2023-09-07T14:16:26.524056Z","iopub.status.idle":"2023-09-07T14:16:26.524563Z","shell.execute_reply":"2023-09-07T14:16:26.524352Z","shell.execute_reply.started":"2023-09-07T14:16:26.524329Z"},"id":"uqcYwWsV4qN5","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class ActorCritic(nn.Module):\n","    \"\"\"ActorCritic Network\"\"\"\n","\n","    def __init__(self, state_dim, hidden_size_1, hidden_size_2, action_dim):\n","        super(ActorCritic, self).__init__()\n","        self.actor = ActorNetwork(\n","            state_dim=state_dim,\n","            hidden_size_1=hidden_size_1,\n","            hidden_size_2=hidden_size_2,\n","            action_dim=action_dim\n","        )\n","        self.critic = CriticNetwork(\n","            state_dim=state_dim,\n","            hidden_size_1=hidden_size_1,\n","            hidden_size_2=hidden_size_2\n","        )\n","        self.device = torch.device(\n","            'cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    def forward(self, state: Data, jitter=1e-20) -> Tuple[torch.Tensor, torch.Tensor]:\n","        \"\"\"\n","        Forward pass, computes action and value\n","        \n","        Parameters\n","        ----------\n","        state : Data\n","            Graph state\n","        jitter : float, optional\n","            Jitter value, by default 1e-20\n","        \n","        Returns\n","        -------\n","        Tuple[torch.Tensor, torch.Tensor]\n","            Tuple of concentration and value\n","        \"\"\"\n","        state = state.to(self.device)\n","        # Actor\n","        probs = self.actor(state)\n","        # Adds jitter to ensure numerical stability\n","        # Use softplus to ensure concentration is positive\n","        concentration = F.softplus(probs).reshape(-1) + jitter\n","        # Critic\n","        value = self.critic(state)\n","        return concentration, value\n","    "]},{"cell_type":"markdown","metadata":{"_cell_guid":"b199b324-e06c-44a7-b00b-1a84c37cf6be","_uuid":"8ab8eb9a-494e-4aa0-a9ed-bba4d9e0f4b4","id":"6mrEeBM-4qN5","trusted":true},"source":["### Agent"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b9f69a32-7c37-4add-a77b-2d67ab34b437","_uuid":"bf6c9b12-ff4d-4964-93ec-192118ca15dc","collapsed":false,"execution":{"iopub.status.busy":"2023-09-07T14:16:26.525621Z","iopub.status.idle":"2023-09-07T14:16:26.527304Z","shell.execute_reply":"2023-09-07T14:16:26.527020Z","shell.execute_reply.started":"2023-09-07T14:16:26.526995Z"},"id":"V4rI4Jrv4qN5","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class Agent:\n","    def __init__(\n","        self, \n","        state_dim: int = HyperParams.STATE_DIM.value, \n","        hidden_size_1: int = HyperParams.HIDDEN_SIZE_1.value, \n","        hidden_size_2: int = HyperParams.HIDDEN_SIZE_2.value,\n","        action_dim: int = HyperParams.ACTION_DIM.value,\n","        lr: float = HyperParams.LR.value,\n","        gamma: float = HyperParams.GAMMA.value,\n","        eps: float = HyperParams.EPS_CLIP.value,\n","        best_reward: float = HyperParams.BEST_REWARD.value):\n","        \"\"\"\n","        Initialize the agent.\n","\n","        Parameters\n","        ----------\n","        state_dim : int\n","            Dimensions of the state, i.e. length of the feature vector\n","        hidden_size_1 : int\n","            First A2C hidden layer size\n","        hidden_size_2 : int\n","            Second A2C hidden layer size\n","        action_dim : int\n","            Dimensions of the action (it is set to 1, to return a tensor N*1)\n","        lr : float\n","            Learning rate\n","        gamma : float\n","            Discount factor\n","        eps : float\n","            Value for clipping the loss function\n","        best_reward : float, optional\n","            Best reward, by default 0.8\n","        \"\"\"\n","        self.state_dim = state_dim\n","        self.hidden_size_1 = hidden_size_1\n","        self.hidden_size_2 = hidden_size_2\n","        self.action_dim = action_dim\n","        self.policy = ActorCritic(\n","            state_dim, hidden_size_1, hidden_size_2, action_dim)\n","        \n","        # Hyperparameters\n","        self.lr = lr\n","        self.gamma = gamma\n","        self.eps = eps\n","        self.best_reward = best_reward\n","        # Print Hyperparameters on console\n","        self.print_hyperparams()\n","        \n","        # Set device\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.policy.to(self.device)\n","        # Set optimizers\n","        self.optimizers = self.configure_optimizers()\n","        \n","        # Initialize lists for logging, it contains: avg_reward, avg_steps per episode\n","        self.log_dict = HyperParams.LOG_DICT.value\n","        \n","        # Training variables\n","        self.obs = None \n","        self.episode_reward = 0\n","        self.done = False\n","        self.step = 0\n","        # action & reward buffer\n","        self.SavedAction = namedtuple('SavedAction', ['log_prob', 'value'])\n","        self.saved_actions = []\n","        self.rewards = []\n","        \n","    def configure_optimizers(self):\n","        \"\"\"\n","        Configure optimizers\n","        \n","        Returns\n","        -------\n","        optimizers : dict\n","            Dictionary of optimizers\n","        \"\"\"\n","        actor_params = list(self.policy.actor.parameters())\n","        critic_params = list(self.policy.critic.parameters())\n","        optimizers = dict()\n","        optimizers['a_optimizer'] = torch.optim.Adam(actor_params, lr=self.lr)\n","        optimizers['c_optimizer'] = torch.optim.Adam(critic_params, lr=self.lr)\n","        return optimizers\n","    \n","    def training(\n","        self,\n","        env: GraphEnvironment,\n","        env_name: str,\n","        detection_alg: str) -> dict:\n","        \"\"\"\n","        Train the agent on the environment, change the target node every 10\n","        episodes and the target community every 100 episodes. The episode ends\n","        when the target node is isolated from the target community, or when the\n","        maximum number of steps is reached.\n","\n","        Parameters\n","        ----------\n","        env : GraphEnvironment\n","            Environment to train the agent on\n","        agent : Agent\n","            Agent to train\n","        env_name : str\n","            Name of the environment\n","        detection_alg : str\n","            Name of the detection algorithm\n","        \n","        Returns\n","        -------\n","        log_dict : dict\n","            Dictionary containing the training logs\n","        \"\"\"\n","        epochs = trange(self.log_dict['train_episodes'])  # epoch iterator\n","        self.policy.train()  # set model in train mode\n","        for i_episode in epochs:\n","            # Change Target Node every 10 episodes\n","            if i_episode % 10 == 0:\n","                env.change_target_node()\n","            # Change Target Community every 100 episodes\n","            if i_episode % 100 == 0:\n","                env.change_target_community()\n","            \n","            # Rewiring the graph until the target node is isolated from the \n","            # target community\n","            while not self.done:\n","                self.rewiring(env)\n","                \n","            # perform on-policy backpropagation\n","            self.a_loss, self.v_loss = self.training_step()\n","            \n","            # Send current statistics to screen\n","            epochs.set_description(\n","                f\"Episode {i_episode+1} \" +\\\n","                f\"| Avg Reward: {self.episode_reward/self.step:.2f} \" +\\\n","                f\"| Avg Steps: {self.step} \" +\\\n","                f\"| Actor Loss: {self.a_loss:.2f} \" +\\\n","                f\"| Critic Loss: {self.v_loss:.2f}\")\n","\n","            # Checkpoint best performing model\n","            if self.episode_reward >= self.best_reward:\n","                self.save_checkpoint(env_name, detection_alg)\n","                self.best_reward = self.episode_reward\n","            \n","            # Log\n","            self.log_dict['train_reward'].append(self.episode_reward)\n","            self.log_dict['train_steps'].append(self.step)\n","            self.log_dict['train_avg_reward'].append(\n","                self.episode_reward/self.step)\n","            self.log_dict['a_loss'].append(self.a_loss)\n","            self.log_dict['v_loss'].append(self.v_loss)\n","            self.log(self.log_dict, env_name, detection_alg)\n","        return self.log_dict\n","    \n","    def rewiring(self, env: GraphEnvironment)->None:\n","        \"\"\"\n","        Rewiring step, select action and take step in environment.\n","\n","        Parameters\n","        ----------\n","        env : GraphEnvironment\n","            Graph environment\n","        \"\"\"\n","        # Select action: return a list of the probabilities of each action\n","        action_rl = self.select_action(self.obs)\n","        torch.cuda.empty_cache()\n","        # Take action in environment\n","        self.obs, reward, self.done = env.step(action_rl)\n","        # Update reward\n","        self.episode_reward += reward\n","        # Store the transition in memory\n","        self.rewards.append(reward)\n","        self.step += 1\n","    \n","    def select_action(self, state: Data) -> int:\n","        \"\"\"\n","        Select action, given a state, using the policy network.\n","        \n","        Parameters\n","        ----------\n","        state : Data\n","            Graph state\n","        \n","        Returns\n","        -------\n","        action: int\n","            Integer representing a node in the graph, it will be the destination\n","            node of the rewiring action\n","        \"\"\"\n","        concentration, value = self.policy.forward(state)\n","        dist = torch.distributions.Categorical(concentration)\n","        action = dist.sample()\n","        self.saved_actions.append(\n","            self.SavedAction(dist.log_prob(action), value))\n","        return action.item()\n","    \n","    def training_step(self) -> Tuple[float, float]:\n","        \"\"\"\n","        Perform a single training step of the A2C algorithm, which involves\n","        computing the actor and critic losses, taking gradient steps, and \n","        resetting the rewards and action buffer.\n","        \n","        Returns\n","        -------\n","        mean_a_loss : float\n","            Mean actor loss\n","        mean_v_loss : float\n","            Mean critic loss\n","        \"\"\"\n","        R = 0\n","        saved_actions = self.saved_actions\n","        policy_losses = []  # list to save actor (policy) loss\n","        value_losses = []  # list to save critic (value) loss\n","        returns = []  # list to save the true values\n","\n","        # calculate the true value using rewards returned from the environment\n","        for r in self.rewards[::-1]:\n","            # calculate the discounted value\n","            R = r + self.gamma * R\n","            # insert to the beginning of the list\n","            returns.insert(0, R)\n","\n","        # Normalize returns by subtracting mean and dividing by standard deviation\n","        # NOTE: May cause NaN problem\n","        if len(returns) > 1:\n","            returns = torch.tensor(returns)\n","            returns = (returns - returns.mean()) / (returns.std() + self.eps)\n","        else:\n","            returns = torch.tensor(returns)\n","\n","        # Computing losses\n","        for (log_prob, value), R in zip(saved_actions, returns):\n","            # Difference between true value and estimated value from critic\n","            advantage = R - value.item()\n","            # calculate actor (policy) loss\n","            policy_losses.append(-log_prob * advantage)\n","            # calculate critic (value) loss using L1 smooth loss\n","            value_losses.append(F.smooth_l1_loss(\n","                value, torch.tensor([R]).to(self.device)))\n","\n","        # take gradient steps\n","        self.optimizers['a_optimizer'].zero_grad()\n","        a_loss = torch.stack(policy_losses).sum()\n","        a_loss.backward()\n","        self.optimizers['a_optimizer'].step()\n","\n","        self.optimizers['c_optimizer'].zero_grad()\n","        v_loss = torch.stack(value_losses).sum()\n","        v_loss.backward()\n","        self.optimizers['c_optimizer'].step()\n","\n","        mean_a_loss = torch.stack(policy_losses).mean().item()\n","        mean_v_loss = torch.stack(value_losses).mean().item()\n","\n","        # reset rewards and action buffer\n","        del self.rewards[:]\n","        del self.saved_actions[:]\n","        return mean_a_loss, mean_v_loss\n","\n","    def print_hyperparams(self):\n","        \"\"\"Print hyperparameters\"\"\"\n","        print(\"*\", \"-\"*18, \"Hyperparameters\", \"-\"*18)\n","        print(\"* State dimension: \", self.state_dim)\n","        print(\"* Action dimension: \", self.action_dim)\n","        print(\"* Learning rate: \", self.lr)\n","        print(\"* Gamma parameter: \", self.gamma)\n","        print(\"* Value for clipping the loss function: \", self.eps)\n","\n","    def save_checkpoint(\n","            self,\n","            env_name: str = 'default',\n","            detection_alg: str = 'default',\n","            log_dir: str = FilePaths.LOG_DIR.value):\n","        \"\"\"Save checkpoint\"\"\"\n","        log_dir = log_dir + env_name  # + '/' + detection_alg\n","        # Check if the directory exists, otherwise create it\n","        Utils.check_dir(log_dir)\n","        path = f'{log_dir}/{env_name}_{detection_alg}.pth'\n","        checkpoint = dict()\n","        checkpoint['model'] = self.policy.state_dict()\n","        for key, value in self.optimizers.items():\n","            checkpoint[key] = value.state_dict()\n","        torch.save(checkpoint, path)\n","\n","    def load_checkpoint(\n","            self,\n","            env_name: str = 'default',\n","            detection_alg: str = 'default',\n","            log_dir: str = FilePaths.LOG_DIR.value):\n","        \"\"\"Load checkpoint\n","        \n","        Parameters\n","        ----------\n","        env_name : str, optional\n","            Environment name, by default 'default'\n","        detection_alg : str, optional\n","            Detection algorithm name, by default 'default'\n","        log_dir : str, optional\n","            Path to the log directory, by default FilePaths.LOG_DIR.value\n","        \"\"\"\n","        log_dir = log_dir + env_name  # + '/' + detection_alg\n","        path = f'{log_dir}/{env_name}_{detection_alg}.pth'\n","        checkpoint = torch.load(path)\n","        self.policy.load_state_dict(checkpoint['model'])\n","        for key, _ in self.optimizers.items():\n","            self.optimizers[key].load_state_dict(checkpoint[key])\n","\n","    def log(\n","            self,\n","            log_dict: dict,\n","            env_name: str = 'default',\n","            detection_alg: str = 'default',\n","            log_dir: str = FilePaths.LOG_DIR.value):\n","        \"\"\"Log data\n","        \n","        Parameters\n","        ----------\n","        log_dict : dict\n","            Dictionary containing the data to be logged\n","        env_name : str, optional\n","            Environment name, by default 'default'\n","        detection_alg : str, optional\n","            Detection algorithm name, by default 'default'\n","        log_dir : str, optional\n","            Path to the log directory, by default FilePaths.LOG_DIR.value\n","        \"\"\"\n","        log_dir = log_dir + env_name  # + '/' + detection_alg\n","        path = f'{log_dir}/{env_name}_{detection_alg}.pth'\n","        torch.save(log_dict, path)\n"]},{"cell_type":"markdown","metadata":{"_cell_guid":"3d97430f-a01e-43dc-b176-9c89aeba9b76","_uuid":"5d0f3e09-b452-468d-88ec-3d86fe84bc84","id":"Pnf9azpI4qN6","trusted":true},"source":["## Execution"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"51cf9745-acf7-4dda-86e8-d2af6379b330","_uuid":"0a274b78-6920-44c3-a17e-2b0c3b9261f9","collapsed":false,"execution":{"iopub.status.busy":"2023-09-07T14:16:26.528777Z","iopub.status.idle":"2023-09-07T14:16:26.529608Z","shell.execute_reply":"2023-09-07T14:16:26.529388Z","shell.execute_reply.started":"2023-09-07T14:16:26.529365Z"},"id":"f6HA13XSGqAn","jupyter":{"outputs_hidden":false},"outputId":"6e088657-588b-4fbe-9b0c-99e135cf7868","trusted":true},"outputs":[],"source":["print(\"*\"*20, \"Setup Information\", \"*\"*20)\n","\n","# ° ------ Graph Setup ------ ° #\n","# ! REAL GRAPH Graph path (change the following line to change the graph)\n","graph_path = FilePaths.KAR.value\n","# Load the graph from the dataset folder\n","graph = Utils.import_mtx_graph(graph_path)\n","# ! SYNTHETIC GRAPH Graph path (change the following line to change the graph)\n","# graph, graph_path = Utils.generate_lfr_benchmark_graph()\n","\n","# Set the environment name as the graph name\n","env_name = graph_path.split(\"/\")[-1].split(\".\")[0]\n","\n","# Print the number of nodes and edges\n","print(\"* Graph Name:\", env_name)\n","print(\"*\", graph)\n","\n","# ° --- Environment Setup --- ° #\n","# ! Define the detection algorithm to use (change the following line to change the algorithm)\n","detection_alg = DetectionAlgorithms.WALK.value\n","print(\"* Community Detection Algorithm:\", detection_alg)\n","# Apply the community detection algorithm on the graph\n","dct = CommunityDetectionAlgorithm(detection_alg)\n","community_structure = dct.compute_community(graph)\n","print(\"* Number of communities found:\", len(community_structure.communities))\n","\n","# Choose one of the communities found by the algorithm, for now we choose \n","# the community with the highest number of nodes\n","community_target = max(community_structure.communities, key=len)\n","idx_community = community_structure.communities.index(community_target)\n","print(\"* Community Target:\\t\", community_target)\n","print(\"* Index Community:\\t\", idx_community)\n","# TEST: Choose a node to remove from the community\n","node_target = community_target[random.randint(0, len(community_target)-1)]\n","print(\"* Nodes Target:\\t\\t\", node_target)\n","\n","# Define the environment\n","env = GraphEnvironment(\n","graph=graph,\n","community=community_target,\n","idx_community=idx_community,\n","node_target=node_target,\n","env_name=env_name,\n","community_detection_algorithm=detection_alg)\n","# Get list of possible actions which can be performed on the graph by the agent\n","n_actions = len(env.possible_actions[\"ADD\"]) + \\\n","len(env.possible_actions[\"REMOVE\"])\n","print(\"* Number of possible actions:\", n_actions)\n","print(\"* Rewiring Budget:\", env.edge_budget)\n","\n","# ° ------ Agent Setup ------ ° #\n","# Define the agent\n","agent = Agent()\n","# Print Hyperparameters of the Agent (inner method)\n","print(\"*\", \"-\"*53)\n","print(\"*\"*20, \"End Information\", \"*\"*20, \"\\n\")\n","\n","log = agent.training(env, env_name, detection_alg)\n","file_path = FilePaths.TEST_DIR.value + env_name + '/' + detection_alg\n","Utils.check_dir(file_path)\n","Utils.save_training(log, env_name, detection_alg, file_path=file_path)\n","Utils.plot_training(log, env_name, detection_alg, file_path=file_path)"]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
