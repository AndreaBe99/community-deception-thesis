{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Community Deception","metadata":{"_cell_guid":"673bb049-4b2f-485d-917a-9ee37a24dc02","_uuid":"0f32c4fd-e251-4197-9445-e1dcbaf2350f","id":"p0PM-10o4qNq","trusted":true}},{"cell_type":"markdown","source":"Connect Google Drive to access the dataset.","metadata":{"id":"MwzQY0W-CVuo"}},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"_cell_guid":"9826e4bc-2669-4e64-9163-59a00fd69e75","_uuid":"24a13315-6d17-45bb-a1aa-da091f1bf4c4","collapsed":false,"id":"ZInwz0n74vdY","jupyter":{"outputs_hidden":false},"outputId":"d3feebd6-18b9-461e-c076-3eccaccf2669","execution":{"iopub.status.busy":"2023-09-20T08:18:32.581680Z","iopub.execute_input":"2023-09-20T08:18:32.582107Z","iopub.status.idle":"2023-09-20T08:18:32.608808Z","shell.execute_reply.started":"2023-09-20T08:18:32.582073Z","shell.execute_reply":"2023-09-20T08:18:32.607778Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Install Pytorch Geometric","metadata":{"_cell_guid":"767eccaf-5a8b-4a3d-8fd9-a6c7b0e67d80","_uuid":"0f6e823a-2475-4d31-9c78-96fbbb666d33","id":"fMmiVKrL4qNt","trusted":true}},{"cell_type":"markdown","source":"If we are on Kaggle we need to run the following cells to install Pytorch Geometric","metadata":{"_cell_guid":"92deff0d-cd46-44c5-8422-6363ab12964d","_uuid":"70ba7b9f-bbfd-44ed-8620-976e97ae2c8b","id":"TuaAoPQU4qNu","trusted":true}},{"cell_type":"code","source":"import torch\nimport os\n\nos.environ[\"TORCH\"] = torch.__version__\n\n# On Colab we can have TORCH+CUDA on os.environ[\"TORCH\"]\n\n# Check if there is the cuda version on TORCH\nif torch.cuda.is_available():\n    print(\"CUDA is available\")\n    print(torch.version.cuda)\n    if \"+\" not in os.environ[\"TORCH\"]:\n        os.environ[\"TORCH\"] += \"+cu\" + \\\n            torch.version.cuda.replace(\".\", \"\")\n\nprint(os.environ[\"TORCH\"])","metadata":{"_cell_guid":"c6f4e319-9760-4147-a0cc-191f24b61b77","_uuid":"9646e447-62cf-4f23-a665-926e53a61479","collapsed":false,"id":"qhb60JfQ4qNu","jupyter":{"outputs_hidden":false},"outputId":"d2f0571f-e5d9-4c9b-b2e3-76c8401d98cb","execution":{"iopub.status.busy":"2023-09-20T08:18:32.610856Z","iopub.execute_input":"2023-09-20T08:18:32.611306Z","iopub.status.idle":"2023-09-20T08:18:35.581522Z","shell.execute_reply.started":"2023-09-20T08:18:32.611265Z","shell.execute_reply":"2023-09-20T08:18:35.580587Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"2.0.0+cpu\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Install torch geometric and optional dependencies:","metadata":{"id":"6gvVZy4LCVus"}},{"cell_type":"code","source":"! pip install torch_geometric\n# Optional dependencies:\n# ! pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\n# ! pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n# ! pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-${TORCH}.html\n! pip install pyg_lib torch_scatter torch_sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n\n# Graph\n# ! pip install cugraph-cu11 --extra-index-url=https://pypi.ngc.nvidia.com\n! pip install igraph\n! pip install cdlib[C]\n! pip install karateclub","metadata":{"_cell_guid":"95a56f18-f34f-4aa7-9bbb-50f6663d0f2e","_uuid":"49338a06-0521-496f-a6f4-531d3d55ae04","collapsed":false,"id":"5xrzyr2i4qNw","jupyter":{"outputs_hidden":false},"outputId":"c0ebca8c-ca4d-4d8a-cfb4-800333737150","scrolled":true,"execution":{"iopub.status.busy":"2023-09-20T08:18:35.583173Z","iopub.execute_input":"2023-09-20T08:18:35.583728Z","iopub.status.idle":"2023-09-20T08:22:12.346050Z","shell.execute_reply.started":"2023-09-20T08:18:35.583698Z","shell.execute_reply":"2023-09-20T08:22:12.345090Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting torch_geometric\n  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (4.65.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (1.23.5)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (1.11.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.1.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (2.31.0)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.0.9)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (1.2.2)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (5.9.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch_geometric) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (2023.5.7)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (3.1.0)\nBuilding wheels for collected packages: torch_geometric\n  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=ed2d40214f23c1358ca03e410f79736b8845a977559d034ab92b40d52a73c5c1\n  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\nSuccessfully built torch_geometric\nInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.3.1\nLooking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\nCollecting pyg_lib\n  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/pyg_lib-0.2.0%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (627 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m627.0/627.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting torch_scatter\n  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.1%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (504 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m504.1/504.1 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting torch_sparse\n  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.17%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (1.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch_sparse) (1.11.1)\nRequirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from scipy->torch_sparse) (1.23.5)\nInstalling collected packages: torch_scatter, pyg_lib, torch_sparse\nSuccessfully installed pyg_lib-0.2.0+pt20cpu torch_scatter-2.1.1+pt20cpu torch_sparse-0.6.17+pt20cpu\nRequirement already satisfied: igraph in /opt/conda/lib/python3.10/site-packages (0.10.5)\nRequirement already satisfied: texttable>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from igraph) (1.6.7)\nCollecting cdlib[C]\n  Downloading cdlib-0.3.0-py3-none-any.whl (230 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.3/230.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from cdlib[C]) (1.23.5)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from cdlib[C]) (3.7.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from cdlib[C]) (1.2.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from cdlib[C]) (4.65.0)\nRequirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.10/site-packages (from cdlib[C]) (3.1)\nCollecting demon (from cdlib[C])\n  Downloading demon-2.0.6-py3-none-any.whl (7.3 kB)\nRequirement already satisfied: python-louvain>=0.16 in /opt/conda/lib/python3.10/site-packages (from cdlib[C]) (0.16)\nCollecting nf1 (from cdlib[C])\n  Downloading nf1-0.0.4-py3-none-any.whl (18 kB)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from cdlib[C]) (1.11.1)\nRequirement already satisfied: pulp in /opt/conda/lib/python3.10/site-packages (from cdlib[C]) (2.7.0)\nRequirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from cdlib[C]) (0.12.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from cdlib[C]) (1.5.3)\nCollecting eva-lcd (from cdlib[C])\n  Downloading eva_lcd-0.1.1-py3-none-any.whl (9.2 kB)\nCollecting bimlpa (from cdlib[C])\n  Downloading bimlpa-0.1.2-py3-none-any.whl (7.0 kB)\nCollecting markov-clustering (from cdlib[C])\n  Downloading markov_clustering-0.0.6.dev0-py3-none-any.whl (6.3 kB)\nRequirement already satisfied: python-igraph>=0.10 in /opt/conda/lib/python3.10/site-packages (from cdlib[C]) (0.10.5)\nCollecting angelcommunity (from cdlib[C])\n  Downloading angelcommunity-2.0.0-py3-none-any.whl (10 kB)\nRequirement already satisfied: pooch in /opt/conda/lib/python3.10/site-packages (from cdlib[C]) (1.6.0)\nCollecting dynetx (from cdlib[C])\n  Downloading dynetx-0.3.2-py3-none-any.whl (39 kB)\nCollecting thresholdclustering (from cdlib[C])\n  Downloading thresholdclustering-1.1-py3-none-any.whl (5.3 kB)\nRequirement already satisfied: python-Levenshtein in /opt/conda/lib/python3.10/site-packages (from cdlib[C]) (0.21.1)\nCollecting infomap>=1.3.0 (from cdlib[C])\n  Downloading infomap-2.7.1.tar.gz (263 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.1/263.1 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: wurlitzer>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from cdlib[C]) (3.0.3)\nCollecting GraphRicciCurvature (from cdlib[C])\n  Downloading GraphRicciCurvature-0.5.3.1-py3-none-any.whl (23 kB)\nCollecting networkit (from cdlib[C])\n  Downloading networkit-10.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting pycombo (from cdlib[C])\n  Downloading pycombo-0.1.7.tar.gz (136 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.6/136.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting leidenalg (from cdlib[C])\n  Downloading leidenalg-0.10.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: igraph==0.10.5 in /opt/conda/lib/python3.10/site-packages (from python-igraph>=0.10->cdlib[C]) (0.10.5)\nRequirement already satisfied: texttable>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from igraph==0.10.5->python-igraph>=0.10->cdlib[C]) (1.6.7)\nRequirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from angelcommunity->cdlib[C]) (0.18.3)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from dynetx->cdlib[C]) (5.1.1)\nRequirement already satisfied: cython in /opt/conda/lib/python3.10/site-packages (from GraphRicciCurvature->cdlib[C]) (0.29.35)\nCollecting pot>=0.8.0 (from GraphRicciCurvature->cdlib[C])\n  Downloading POT-0.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (789 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m790.0/790.0 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from GraphRicciCurvature->cdlib[C]) (21.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->cdlib[C]) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->cdlib[C]) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->cdlib[C]) (4.40.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->cdlib[C]) (1.4.4)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->cdlib[C]) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->cdlib[C]) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->cdlib[C]) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->cdlib[C]) (2023.3)\nRequirement already satisfied: appdirs>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from pooch->cdlib[C]) (1.4.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch->cdlib[C]) (2.31.0)\nRequirement already satisfied: pybind11<3.0.0,>=2.6.1 in /opt/conda/lib/python3.10/site-packages (from pycombo->cdlib[C]) (2.10.4)\nRequirement already satisfied: Levenshtein==0.21.1 in /opt/conda/lib/python3.10/site-packages (from python-Levenshtein->cdlib[C]) (0.21.1)\nRequirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from Levenshtein==0.21.1->python-Levenshtein->cdlib[C]) (3.1.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->cdlib[C]) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->cdlib[C]) (3.1.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->cdlib[C]) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch->cdlib[C]) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch->cdlib[C]) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch->cdlib[C]) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch->cdlib[C]) (2023.5.7)\nBuilding wheels for collected packages: infomap, pycombo\n  Building wheel for infomap (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for infomap: filename=infomap-2.7.1-cp310-cp310-linux_x86_64.whl size=767695 sha256=4d8acd9307adf5515b95f8a87c7026295290b176dd2e12ea8b9dd66b385cdb13\n  Stored in directory: /root/.cache/pip/wheels/e4/01/53/fd7c62079098140cd582b999592b4592c0dad7300cac32b6e1\n  Building wheel for pycombo (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pycombo: filename=pycombo-0.1.7-cp310-cp310-manylinux_2_31_x86_64.whl size=205045 sha256=b1bcc521ef3dbc97bbd5941d40bfba4780491aa3d4954df30b2544c0a2fba972\n  Stored in directory: /root/.cache/pip/wheels/21/90/69/e7f601be9740da0df241d6b15d29c7d885896dd84a8eeaeaf2\nSuccessfully built infomap pycombo\nInstalling collected packages: thresholdclustering, pycombo, infomap, eva-lcd, dynetx, demon, pot, networkit, leidenalg, nf1, markov-clustering, GraphRicciCurvature, bimlpa, angelcommunity, cdlib\nSuccessfully installed GraphRicciCurvature-0.5.3.1 angelcommunity-2.0.0 bimlpa-0.1.2 cdlib-0.3.0 demon-2.0.6 dynetx-0.3.2 eva-lcd-0.1.1 infomap-2.7.1 leidenalg-0.10.1 markov-clustering-0.0.6.dev0 networkit-10.1 nf1-0.0.4 pot-0.9.1 pycombo-0.1.7 thresholdclustering-1.1\nCollecting karateclub\n  Downloading karateclub-1.3.3.tar.gz (64 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting numpy<1.23.0 (from karateclub)\n  Downloading numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting networkx<2.7 (from karateclub)\n  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting decorator==4.4.2 (from karateclub)\n  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from karateclub) (4.65.0)\nRequirement already satisfied: python-louvain in /opt/conda/lib/python3.10/site-packages (from karateclub) (0.16)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from karateclub) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from karateclub) (1.11.1)\nCollecting pygsp (from karateclub)\n  Downloading PyGSP-0.5.1-py2.py3-none-any.whl (1.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: gensim>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from karateclub) (4.3.1)\nCollecting pandas<=1.3.5 (from karateclub)\n  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from karateclub) (1.16.0)\nRequirement already satisfied: python-Levenshtein in /opt/conda/lib/python3.10/site-packages (from karateclub) (0.21.1)\nRequirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim>=4.0.0->karateclub) (6.3.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.10/site-packages (from pandas<=1.3.5->karateclub) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.10/site-packages (from pandas<=1.3.5->karateclub) (2023.3)\nRequirement already satisfied: Levenshtein==0.21.1 in /opt/conda/lib/python3.10/site-packages (from python-Levenshtein->karateclub) (0.21.1)\nRequirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from Levenshtein==0.21.1->python-Levenshtein->karateclub) (3.1.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->karateclub) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->karateclub) (3.1.0)\nBuilding wheels for collected packages: karateclub\n  Building wheel for karateclub (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for karateclub: filename=karateclub-1.3.3-py3-none-any.whl size=102008 sha256=b3203e2445e3102f87160ba42adb7151d9371c14b4ac4169b20438ea3f066459\n  Stored in directory: /root/.cache/pip/wheels/62/bd/af/17e7ca6ba0ed144d22502780f5c0660a8e4985939dc6973a81\nSuccessfully built karateclub\nInstalling collected packages: numpy, networkx, decorator, pandas, pygsp, karateclub\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.23.5\n    Uninstalling numpy-1.23.5:\n      Successfully uninstalled numpy-1.23.5\n  Attempting uninstall: networkx\n    Found existing installation: networkx 3.1\n    Uninstalling networkx-3.1:\n      Successfully uninstalled networkx-3.1\n  Attempting uninstall: decorator\n    Found existing installation: decorator 5.1.1\n    Uninstalling decorator-5.1.1:\n      Successfully uninstalled decorator-5.1.1\n  Attempting uninstall: pandas\n    Found existing installation: pandas 1.5.3\n    Uninstalling pandas-1.5.3:\n      Successfully uninstalled pandas-1.5.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nangelcommunity 2.0.0 requires networkx>=3.0, but you have networkx 2.6.3 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\nbeatrix-jupyterlab 2023.621.222118 requires jupyter-server~=1.16, but you have jupyter-server 2.6.0 which is incompatible.\ncdlib 0.3.0 requires networkx>=3.0, but you have networkx 2.6.3 which is incompatible.\nchex 0.1.81 requires numpy>=1.25.0, but you have numpy 1.22.4 which is incompatible.\nfeaturetools 1.26.0 requires pandas<2.0.0,>=1.5.0, but you have pandas 1.3.5 which is incompatible.\njupyterlab-lsp 4.2.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nmomepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.22.4 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.1 which is incompatible.\nscikit-image 0.21.0 requires networkx>=2.8, but you have networkx 2.6.3 which is incompatible.\nwoodwork 0.24.0 requires pandas<2.0.0,>=1.4.3, but you have pandas 1.3.5 which is incompatible.\nxarray 2023.6.0 requires pandas>=1.4, but you have pandas 1.3.5 which is incompatible.\nydata-profiling 4.3.1 requires scipy<1.11,>=1.4.1, but you have scipy 1.11.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed decorator-4.4.2 karateclub-1.3.3 networkx-2.6.3 numpy-1.22.4 pandas-1.3.5 pygsp-0.5.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**IMPORTANT!!!**\nAfter the libraries installation, restart the runtime and start executing the cells below","metadata":{"_cell_guid":"6c434269-bbe5-471e-9837-32eb4797b632","_uuid":"96df44d7-6753-48a0-bdfa-f064dcfc38a8","id":"ax8CbJZsgSsW","trusted":true}},{"cell_type":"markdown","source":"## Import Libraries","metadata":{"_cell_guid":"75539a6d-e94f-44dd-b140-54371e7c6bc4","_uuid":"fe95edcb-9a91-483a-9fde-a986591481b9","id":"z5ImUEyx4qNx","trusted":true}},{"cell_type":"code","source":"# Import torch and os another time to reset the colab enviroment after PyG installation\nfrom IPython.display import FileLink, display\nimport subprocess\nimport torch\nimport os\nimport gc\n\n# Typing\nfrom typing import List, Tuple, Set, Callable\nfrom collections import Counter, namedtuple\n\n# Deep Learning\nfrom torch_geometric.utils import from_networkx\nfrom torch_geometric.data import Data\nfrom torch_geometric.data import Batch\nfrom torch_geometric.nn import GCNConv, GATConv\nfrom torch_geometric.nn import global_mean_pool\nfrom torch.distributions import MultivariateNormal\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport pandas as pd\nimport scipy\n\n# Graph\nfrom karateclub import GL2Vec\nfrom cdlib import algorithms\nimport cdlib\nimport networkx as nx\nimport igraph as ig\n\n# cuGraph\n# import cugraph as cnx\n\n\n# Misc\nfrom statistics import mean\nfrom enum import Enum\nfrom tqdm import trange\nimport math\nimport random\nimport json\nimport time\n\n# Plot\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('default')\n","metadata":{"_cell_guid":"11654998-cc12-44b6-be88-72bc30a27d72","_uuid":"bf86a857-762d-473f-ac47-b214ce5ca0c9","collapsed":false,"id":"39avPlWH4qNx","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-20T08:40:47.556766Z","iopub.execute_input":"2023-09-20T08:40:47.557279Z","iopub.status.idle":"2023-09-20T08:40:47.570670Z","shell.execute_reply.started":"2023-09-20T08:40:47.557224Z","shell.execute_reply":"2023-09-20T08:40:47.569500Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"markdown","source":"## Utils","metadata":{"_cell_guid":"5e1042f3-4d76-4247-be62-b76938b0a84b","_uuid":"aa35c47a-e038-4d07-a98c-8b122c860ccf","id":"5VGevrvC4qNy","trusted":true}},{"cell_type":"code","source":"# Only for the notebook\nTRAIN = False\n# Set to True to test the results with the baselines algorithms\nTEST = True","metadata":{"execution":{"iopub.status.busy":"2023-09-20T08:40:47.573008Z","iopub.execute_input":"2023-09-20T08:40:47.573630Z","iopub.status.idle":"2023-09-20T08:40:47.596146Z","shell.execute_reply.started":"2023-09-20T08:40:47.573589Z","shell.execute_reply":"2023-09-20T08:40:47.595225Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"class FilePaths(Enum):\n    \"\"\"Class to store file paths for data and models\"\"\"\n    # ° Local\n    # DATASETS_DIR = 'dataset/data'\n    # LOG_DIR    = 'src/logs/'\n    # TEST_DIR = 'test/'\n    # ° Kaggle\n    DATASETS_DIR = '/kaggle/input/network-community'\n    LOG_DIR = '/kaggle/working/logs/'\n    TEST_DIR = '/kaggle/working/test/'\n    # ° Google Colab\n    # DATASETS_DIR = \"/content/drive/MyDrive/Sapienza/Tesi/Datasets\"\n    # LOG_DIR = \"/content/drive/MyDrive/Sapienza/Tesi/Logs/\"\n    # TEST_DIR = \"/content/drive/MyDrive/Sapienza/Tesi/Test/\"\n    \n    # Folder of the trained model\n    TRAINED_MODEL = \"/kaggle/input/test-community-deception-model/gcnconv_model.pth\"\n    \n    # Dataset file paths\n    KAR = DATASETS_DIR + '/kar.mtx'\n    DOL = DATASETS_DIR + '/dol.mtx'\n    MAD = DATASETS_DIR + '/mad.mtx'\n    LESM = DATASETS_DIR + '/lesm.mtx'\n    POLB = DATASETS_DIR + '/polb.mtx'\n    WORDS = DATASETS_DIR + '/words.mtx'\n    ERDOS = DATASETS_DIR + '/erdos.mtx'\n    POW = DATASETS_DIR + '/pow.mtx'\n    FB_75 = DATASETS_DIR + '/fb-75.mtx'\n    DBLP = DATASETS_DIR + '/dblp.mtx'\n    ASTR = DATASETS_DIR + '/astr.mtx'\n    AMZ = DATASETS_DIR + '/amz.mtx'\n    YOU = DATASETS_DIR + '/you.mtx'\n    ORK = DATASETS_DIR + '/ork.mtx'\n\n\nclass DetectionAlgorithmsNames(Enum):\n    \"\"\"\n    Enum class for the detection algorithms\n    \"\"\"\n    LOUV = \"louvain\"\n    WALK = \"walktrap\"\n    GRE = \"greedy\"\n    INF = \"infomap\"\n    LAB = \"label_propagation\"\n    EIG = \"eigenvector\"\n    BTW = \"edge_betweenness\"\n    SPIN = \"spinglass\"\n    OPT = \"optimal\"\n    SCD = \"scalable_community_detection\"\n\n\nclass SimilarityFunctionsNames(Enum):\n    \"\"\"\n    Enum class for the similarity functions\n    \"\"\"\n    # Community similarity functions\n    JAC = \"jaccard\"\n    OVE = \"overlap\"\n    SOR = \"sorensen\"\n    # Graph similarity functions\n    GED = \"ged\"  # Graph edit distance\n    JAC_1 = \"jaccard_1\"\n    JAC_2 = \"jaccard_2\"\n\n\nclass HyperParams(Enum):\n    \"\"\"Hyperparameters for the Environment\"\"\"\n    # ! REAL GRAPH Graph path (change the following line to change the graph)\n    GRAPH_NAME = FilePaths.KAR.value\n    # ! Define the detection algorithm to use (change the following line to change the algorithm)\n    DETECTION_ALG_NAME = DetectionAlgorithmsNames.GRE.value\n    # Multiplier for the rewiring action number, i.e. (mean_degree * BETA)\n    BETA = 3\n    # ! Strength of the deception constraint, value between 0 (hard) and 1 (soft) \n    TAU = 0.5\n    # ° Hyperparameters  Testing ° #\n    # ! Weight to balance the penalty in the reward\n    # The higher its value the more importance the penalty will have\n    LAMBDA = [0.1] # [0.01, 0.1, 1]\n    # ! Weight to balance the two metrics in the definition of the penalty\n    # The higher its value the more importance the distance between communities \n    # will have, compared with the distance between graphs\n    ALPHA = [0.7] # [0.3, 0.5, 0.7]\n    # Multiplier for the number of maximum steps allowed\n    MAX_STEPS_MUL = 2\n    \n    \"\"\" Graph Encoder Parameters \"\"\"\"\"\n    EMBEDDING_DIM = 128 # 256\n\n    \"\"\" Agent Parameters\"\"\"\n    # Networl Architecture\n    HIDDEN_SIZE_1 = 64\n    HIDDEN_SIZE_2 = 64\n    # Hyperparameters for the ActorCritic\n    EPS_CLIP = np.finfo(np.float32).eps.item()  # 0.2\n    BEST_REWARD = 0.7  # -np.inf\n    # ° Hyperparameters  Testing ° #\n    # ! Learning rate, it controls how fast the network learns\n    LR = [1e-4] # [1e-7, 1e-4, 1e-1]\n    # ! Discount factor\n    GAMMA = [0.9] # [0.9, 0.95]\n    \n    \"\"\" Training Parameters \"\"\"\n    # Number of episodes to collect experience\n    MAX_EPISODES = 1000\n    # Dictonary for logging\n    LOG_DICT = {\n        # List of rewards per episode\n        'train_reward_list': [],\n        # Avg reward per episode, with the last value multiplied per 10 if the \n        # goal is reached\n        'train_reward_mul': [],\n        # Total reward per episode\n        'train_reward': [],\n        # Number of steps per episode\n        'train_steps': [],\n        # Average reward per episode\n        'train_avg_reward': [],\n        # Average Actor loss per episode\n        'a_loss': [],\n        # Average Critic loss per episode\n        'v_loss': [],\n        # set max number of training episodes\n        'train_episodes': MAX_EPISODES,\n    }\n    \n    \"\"\"Evaluation Parameters\"\"\"\n    # ! Change the following parameters according to the hyperparameters to test\n    STEPS_EVAL = 1000\n    LR_EVAL = LR[0]\n    GAMMA_EVAL = GAMMA[0]\n    LAMBDA_EVAL = LAMBDA[0]\n    ALPHA_EVAL = ALPHA[0]\n    # Algorithms to evaluate\n    ALGS_EVAL = [\"Roam\",  \"Random\", \"Degree\", \"Agent\"]\n    # Metrics for each algorithm\n    METRICS_EVAL = [\"goal\", \"nmi\", \"time\", \"steps\"]\n    \n    \"\"\"Graph Generation Parameters\"\"\"\n    # ! Change the following parameters to modify the graph\n    # Number of nodes\n    N_NODE = 300\n    # Power law exponent for the degree distribution of the created graph.\n    TAU1 = 2\n    # Power law exponent for the community size distribution in the created graph.\n    TAU2 = 1.1\n    # Fraction of inter-community edges incident to each node.\n    MU = 0.1\n\n    # Desired average degree of nodes in the created graph.\n    AVERAGE_DEGREE = int(0.05 * N_NODE)  # 20\n    # Minimum degree of nodes in the created graph\n    MIN_DEGREE = None  # 30\n    # Maximum degree of nodes in the created graph\n    MAX_DEGREE = int(0.19 * N_NODE)\n\n    # Minimum size of communities in the graph.\n    MIN_COMMUNITY = int(0.05 * N_NODE)\n    # Maximum size of communities in the graph.\n    MAX_COMMUNITY = int(0.2 * N_NODE)\n\n    # Maximum number of iterations to try to create the community sizes, degree distribution, and community affiliations.\n    MAX_ITERS = 5000\n    # Seed for the random number generator.\n    SEED = 10\n\n\nclass Utils:\n    \"\"\"Class to store utility functions\"\"\"\n\n    @staticmethod\n    def import_mtx_graph(file_path: str) -> nx.Graph:\n        \"\"\"\n        Import a graph from a .mtx file\n\n        Parameters\n        ----------\n        file_path : str\n            File path of the .mtx file\n\n        Returns\n        -------\n        nx.Graph\n            Graph imported from the .mtx file\n        \"\"\"\n        try:\n            graph_matrix = scipy.io.mmread(file_path)\n            graph = nx.Graph(graph_matrix)\n            for node in graph.nodes:\n                # graph.nodes[node]['name'] = node\n                graph.nodes[node]['num_neighbors'] = len(\n                    list(graph.neighbors(node)))\n            return graph\n        except Exception as exception:\n            print(\"Error: \", exception)\n            return None\n    \n    @staticmethod\n    def generate_lfr_benchmark_graph(\n        n: int=HyperParams.N_NODE.value,\n        tau1: float=HyperParams.TAU1.value,\n        tau2: float=HyperParams.TAU2.value,\n        mu: float=HyperParams.MU.value,   \n        average_degree: int = HyperParams.AVERAGE_DEGREE.value,\n        min_degree: int=HyperParams.MIN_DEGREE.value,\n        max_degree: int=HyperParams.MAX_DEGREE.value,\n        min_community: int=HyperParams.MIN_COMMUNITY.value,\n        max_community: int=HyperParams.MAX_COMMUNITY.value,\n        max_iters: int=HyperParams.MAX_ITERS.value,\n        seed: int=HyperParams.SEED.value)->Tuple[nx.Graph, str]:\n        \"\"\"\n        Generate a LFR benchmark graph for community detection algorithms.\n\n        Parameters\n        ----------\n        n : int, optional\n            Number of nodes, by default 500\n        tau1 : float, optional\n            _description_, by default 3\n        tau2 : float, optional\n            _description_\n        mu : float, optional\n            Mixing parameter, by default 0.1\n        average_degree : int, optional\n            Average degree of the nodes, by default 20\n        min_degree : int, optional\n            Minimum degree of the nodes, by default 20\n        max_degree : int, optional\n            Maximum degree of the nodes, by default 50\n        min_community : int, optional\n            Minimum number of communities, by default 10\n        max_community : int, optional\n            Maximum number of communities, by default 50\n        max_iters : int, optional\n            Maximum number of iterations, by default 5000\n        seed : int, optional\n            Seed for the random number generator, by default 10\n\n        Returns\n        -------\n        nx.Graph\n            Synthetic graph generated with the LFR benchmark\n        file_path : str\n            Path to the file where the graph is saved\n        \"\"\"\n        graph = nx.generators.community.LFR_benchmark_graph(\n            n=n,\n            tau1=tau1,\n            tau2=tau2,\n            mu=mu,\n            average_degree=average_degree,\n            min_degree=min_degree,\n            max_degree=max_degree,\n            min_community=min_community,\n            max_community=max_community,\n            max_iters=max_iters,\n            seed=seed)\n        # file_path = FilePaths.DATASETS_DIR.value + f\"/lfr_benchmark_node-{n}.mtx\"\n        # ! FOR KAGGLE NOTEBOOK\n        file_path = f\"/kaggle/working/lfr_benchmark_node-{n}.mtx\"\n        nx.write_edgelist(graph, file_path, data=False)\n        # Delete community attribute from the nodes to handle PyG compatibility\n        for node in graph.nodes:\n            if 'community' in graph.nodes[node]:\n                del graph.nodes[node]['community']\n        for edge in graph.edges:\n            graph.edges[edge]['weight'] = 1\n        return graph, file_path\n        \n    @staticmethod\n    def check_dir(path: str):\n        \"\"\"\n        Check if the directory exists, if not create it.\n\n        Parameters\n        ----------\n        path : str\n            Path to the directory\n        \"\"\"\n        if not os.path.exists(path):\n            os.makedirs(path)\n    \n    @staticmethod\n    def plot_training(\n        log: dict, \n        env_name: str, \n        detection_algorithm: str,\n        file_path: str,\n        window_size: int=int(HyperParams.MAX_EPISODES.value/100)):\n        \"\"\"Plot the training results\n\n        Parameters\n        ----------\n        log : dict\n            Dictionary containing the training logs\n        env_name : str\n            Name of the environment\n        detection_algorithm : str\n            Name of the detection algorithm\n        file_path : str\n            Path to save the plot\n        window_size : int, optional\n            Size of the rolling window, by default 100\n        \"\"\"\n        def plot_seaborn(\n                df: pd.DataFrame,\n                path: str,\n                env_name: str,\n                detection_algorithm: str,\n                labels: Tuple[str, str],\n                colors: Tuple[str, str]) -> None:\n            sns.set_style(\"darkgrid\")\n            sns.lineplot(data=df, x=\"Episode\", y=labels[0], color=colors[0])\n            sns.lineplot(data=df, x=\"Episode\", y=labels[1], color=colors[1],\n                        estimator=\"mean\", errorbar=None)\n            plt.title(\n                f\"Training on {env_name} graph with {detection_algorithm} algorithm\")\n            plt.xlabel(\"Episode\")\n            plt.ylabel(labels[0])\n            plt.savefig(path)\n            plt.clf()\n        \n        if window_size < 1:\n            window_size = 1\n        df = pd.DataFrame({\n            \"Episode\": range(len(log[\"train_avg_reward\"])),\n            \"Avg Reward\": log[\"train_avg_reward\"],\n            \"Steps per Epoch\": log[\"train_steps\"],\n            \"Goal Reward\": log[\"train_reward_mul\"],\n            \"Goal Reached\": [1/log[\"train_steps\"][i] if log[\"train_reward_list\"][i][-1]\n                > 1 else 0 for i in range(len(log[\"train_steps\"]))],\n        })\n        df[\"Rolling_Avg_Reward\"] = df[\"Avg Reward\"].rolling(window_size).mean()\n        df[\"Rolling_Steps\"] = df[\"Steps per Epoch\"].rolling(window_size).mean()\n        df[\"Rolling_Goal_Reward\"] = df[\"Goal Reward\"].rolling(window_size).mean()\n        df[\"Rolling_Goal_Reached\"] = df[\"Goal Reached\"].rolling(window_size).mean()\n        plot_seaborn(\n            df,\n            file_path+\"/training_reward.png\",\n            env_name,\n            detection_algorithm,\n            (\"Avg Reward\", \"Rolling_Avg_Reward\"),\n            (\"lightsteelblue\", \"darkblue\"),\n        )\n        plot_seaborn(\n            df,\n            file_path+\"/training_steps.png\",\n            env_name,\n            detection_algorithm,\n            (\"Steps per Epoch\", \"Rolling_Steps\"),\n            (\"thistle\", \"purple\"),\n        )\n        plot_seaborn(\n            df,\n            file_path+\"/training_goal_reward.png\",\n            env_name,\n            detection_algorithm,\n            (\"Goal Reward\", \"Rolling_Goal_Reward\"),\n            (\"darkgray\", \"black\"),\n        )\n        plot_seaborn(\n            df,\n            file_path+\"/training_goal_reached.png\",\n            env_name,\n            detection_algorithm,\n            (\"Goal Reached\", \"Rolling_Goal_Reached\"),\n            (\"darkgray\", \"black\"),\n        )\n\n        df = pd.DataFrame({\n            \"Episode\": range(len(log[\"a_loss\"])),\n            \"Actor Loss\": log[\"a_loss\"],\n            \"Critic Loss\": log[\"v_loss\"],\n        })\n        df[\"Rolling_Actor_Loss\"] = df[\"Actor Loss\"].rolling(window_size).mean()\n        df[\"Rolling_Critic_Loss\"] = df[\"Critic Loss\"].rolling(window_size).mean()\n        plot_seaborn(\n            df,\n            file_path+\"/training_a_loss.png\",\n            env_name,\n            detection_algorithm,\n            (\"Actor Loss\", \"Rolling_Actor_Loss\"),\n            (\"palegreen\", \"darkgreen\"),\n        )\n        plot_seaborn(\n            df,\n            file_path+\"/training_v_loss.png\",\n            env_name,\n            detection_algorithm,\n            (\"Critic Loss\", \"Rolling_Critic_Loss\"),\n            (\"lightcoral\", \"darkred\"),\n        )\n\n        \n    ############################################################################\n    #                               EVALUATION                                 #\n    ############################################################################   \n    @staticmethod   \n    def get_new_community(\n        node_target: int,\n        new_community_structure: List[List[int]]) -> List[int]:\n        \"\"\"\n        Search the community target in the new community structure after \n        deception. As new community target after the action, we consider the \n        community that contains the target node, if this community satisfies \n        the deception constraint, the episode is finished, otherwise not.\n\n        Parameters\n        ----------\n        node_target : int\n            Target node to be hidden from the community\n        new_community_structure : List[List[int]]\n            New community structure after deception\n\n        Returns\n        -------\n        List[int]\n            New community target after deception\n        \"\"\"\n        for community in new_community_structure.communities:\n            if node_target in community:\n                return community\n        raise ValueError(\"Community not found\")\n    \n    @staticmethod\n    def check_goal(\n            env,#: GraphEnvironment,\n            node_target: int,\n            old_community: int,\n            new_community: int) -> int:\n        \"\"\"\n        Check if the goal of hiding the target node was achieved\n\n        Parameters\n        ----------\n        env : GraphEnvironment\n            Environment of the agent\n        node_target : int\n            Target node\n        old_community : int\n            Original community of the target node\n        new_community : int\n            New community of the target node\n        similarity_function : Callable\n            Similarity function to use\n            \n        Returns\n        -------\n        int\n            1 if the goal was achieved, 0 otherwise\n        \"\"\"\n        if len(new_community) == 1:\n            return 1\n        # Copy the communities to avoid modifying the original ones\n        new_community_copy = new_community.copy()\n        new_community_copy.remove(node_target)\n        old_community_copy = old_community.copy()\n        old_community_copy.remove(node_target)\n        # Compute the similarity between the new and the old community\n        similarity = env.community_similarity(\n            new_community_copy,\n            old_community_copy\n        )\n        del new_community_copy, old_community_copy\n        if similarity <= env.tau:\n            return 1\n        return 0\n\n    @staticmethod\n    def initialize_dict(algs: List[str]):\n        \"\"\"\n        Initialize the dictionary for the evaluation\n\n        Parameters\n        ----------\n        algs : List[str]\n            List of algorithms names to evaluate\n        \"\"\"\n        log_dict = dict()\n        \n        for alg in algs:\n            log_dict[alg] = {\n                \"goal\": [],\n                \"nmi\": [],\n                \"time\": [],\n                \"steps\": [],\n            }\n        return log_dict\n    \n    @staticmethod\n    def save_test(log: dict, files_path: str):\n        \"\"\"Save and Plot the testing results\n\n        Parameters\n        ----------\n        log : dict\n            Dictionary containing the training logs\n        files_path : str\n            Path to save the plot\n        \"\"\"\n        file_name = f\"{files_path}/evaluation_results.json\"\n        # Save json file\n        with open(file_name, \"w\", encoding=\"utf-8\") as f:\n            json.dump(log, f, indent=4)\n        \n        # Plot the results\n        # Algorithms\n        list_algs = HyperParams.ALGS_EVAL.value\n        # Metrics for each algorithm\n        metrics = HyperParams.METRICS_EVAL.value\n\n        for metric in metrics:\n            # Create a DataFrame with the mean values of each algorithm for the metric\n            df = pd.DataFrame({\n                \"Algorithm\": list_algs,\n                metric.capitalize(): [mean(log[alg][metric]) for alg in list_algs]\n            })\n            # Create the bar plot with the mean values of each algorithm for the metric\n            sns.set_style(\"darkgrid\")\n            sns.barplot(data=df, x=\"Algorithm\",\n                        y=metric.capitalize(), palette=sns.color_palette(\"Set1\"))\n            plt.title(\n                f\"Evaluation on {log['env']['dataset']} with {log['env']['detection_alg']} algorithm\")\n            plt.xlabel(\"Algorithm\")\n            plt.ylabel(metric.capitalize())\n            plt.savefig(f\"{files_path}/{metric}.png\")\n            plt.clf()","metadata":{"_cell_guid":"21216b4a-7ec5-4f03-9eef-3d1b962e1f7d","_uuid":"2128c3d4-dbf0-4b52-81d1-d9490ba9cf56","collapsed":false,"id":"Pairxi9g4qNy","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-20T08:40:47.799866Z","iopub.execute_input":"2023-09-20T08:40:47.800798Z","iopub.status.idle":"2023-09-20T08:40:47.861872Z","shell.execute_reply.started":"2023-09-20T08:40:47.800742Z","shell.execute_reply":"2023-09-20T08:40:47.860569Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"# Create paths\nUtils.check_dir(FilePaths.LOG_DIR.value)\nUtils.check_dir(FilePaths.TEST_DIR.value)","metadata":{"_cell_guid":"4b08c13f-6d30-4fd3-9db7-d473f48a7962","_uuid":"f6c177fe-444c-4d7a-8bd3-b426f3306d2e","collapsed":false,"id":"tPtypREECVux","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-20T08:40:47.864424Z","iopub.execute_input":"2023-09-20T08:40:47.865169Z","iopub.status.idle":"2023-09-20T08:40:47.871505Z","shell.execute_reply.started":"2023-09-20T08:40:47.865126Z","shell.execute_reply":"2023-09-20T08:40:47.870629Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"markdown","source":"## Community Algorithms","metadata":{"_cell_guid":"18777a8c-0ec0-47fd-be6f-bad8d2620d07","_uuid":"2964b49a-91f3-4d99-a1c8-0950e9e9b53b","id":"iJUWAWt24qNz","trusted":true}},{"cell_type":"markdown","source":"### Community Detection","metadata":{"id":"nwTTb1F-HsRC"}},{"cell_type":"code","source":"class CommunityDetectionAlgorithm(object):\n    \"\"\"Class for the community detection algorithms using CDLIB\"\"\"\n    def __init__(self, alg_name: str) -> None:\n        \"\"\"\n        Initialize the DetectionAlgorithm object\n\n        Parameters\n        ----------\n        alg_name : str\n            The name of the algorithm\n        \"\"\"\n        self.alg_name = alg_name\n\n    def compute_community(self, graph: nx.Graph) -> cdlib.NodeClustering:\n        \"\"\"Compute the community partition of the graph\n\n        Parameters\n        ----------\n        graph : nx.Graph\n            Input graph\n\n        Returns\n        -------\n        cdlib.NodeClustering\n            Cdlib NodeClustering object\n        \"\"\"\n        # Rename DetectionAlgorithms Enum to da for convenience\n        da = DetectionAlgorithmsNames\n        # Choose the algorithm\n        if self.alg_name == da.LOUV.value:\n            return algorithms.louvain(graph)\n        elif self.alg_name == da.WALK.value:\n            return algorithms.walktrap(graph)\n        elif self.alg_name == da.GRE.value:\n            return algorithms.greedy_modularity(graph)\n        elif self.alg_name == da.INF.value:\n            return algorithms.infomap(graph)\n        # elif self.alg_name == da.LAB.value:\n        #    # ! Return a EdgeClustering object\n        #    return algorithms.label_propagation(graph)\n        elif self.alg_name == da.EIG.value:\n            return algorithms.eigenvector(graph)\n        # elif self.alg_name == da.BTW.value:\n        #     return self.compute_btw(graph, args)\n        elif self.alg_name == da.SPIN.value:\n            return algorithms.spinglass(graph)\n        # elif self.alg_name == da.OPT.value:\n        #    return self.compute_opt(graph, args)\n        # elif self.alg_name == da.SCD.value:\n        #    return self.compute_scd(graph)\n        else:\n            raise ValueError('Invalid algorithm name')","metadata":{"_cell_guid":"5ea2d660-1f91-4c56-8897-62ae44700433","_uuid":"a1364c7a-cfc3-4bca-b39b-b117898a0a1c","collapsed":false,"id":"lXOSaaPJ4qN0","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-20T08:40:47.872804Z","iopub.execute_input":"2023-09-20T08:40:47.873122Z","iopub.status.idle":"2023-09-20T08:40:47.884677Z","shell.execute_reply.started":"2023-09-20T08:40:47.873083Z","shell.execute_reply":"2023-09-20T08:40:47.883738Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"markdown","source":"### Community Deception Baselines","metadata":{"id":"pee_D4QvHvII"}},{"cell_type":"markdown","source":"#### Random Hiding","metadata":{"id":"wlGbeHzwH0rJ"}},{"cell_type":"code","source":"class RandomHiding():\n    \n    def __init__(\n        self, \n        env, \n        steps: int, \n        target_community: List[int]):\n        self.env = env\n        self.graph = self.env.original_graph\n        self.steps = steps\n        self.target_node = self.env.node_target\n        self.target_community = target_community\n        self.detection_alg = self.env.detection\n        self.original_community_structure = self.env.original_community_structure\n        self.possible_edges = self.get_possible_action() # self.env.possible_actions\n        # Put all the edges in a list\n        # self.possible_edges = self.env.possible_actions\n        # self.possible_edges = list(self.possible_edges[\"ADD\"]) + list(self.possible_edges[\"REMOVE\"])\n        \n    def get_possible_action(self):\n        # Put all edge between the target node and its neighbors in a list\n        possible_actions_add = []\n        for neighbor in self.graph.neighbors(self.target_node):\n            possible_actions_add.append((self.target_node, neighbor))\n        \n        # Put all the edges that aren't neighbors of the target node in a list\n        possible_actions_remove = []\n        for node in self.graph.nodes():\n            if node != self.target_node and node not in self.graph.neighbors(self.target_node):\n                possible_actions_remove.append((self.target_node, node))\n        possible_action = possible_actions_add + possible_actions_remove\n        return possible_action\n    \n    def hide_target_node_from_community(self)->tuple:\n        \"\"\"\n        Hide the target node from the target community by rewiring its edges, \n        choosing randomly between adding or removing an edge.\n        \n        Returns\n        -------\n        G_prime: nx.Graph\n        \"\"\"\n        graph = self.graph.copy()\n        done = False\n        while self.steps > 0 and not done:\n            # Random choose a edge from the possible edges\n            edge = self.possible_edges.pop()\n            if graph.has_edge(*edge):\n                # Remove the edge\n                graph.remove_edge(*edge)\n            else:\n                # Add the edge\n                graph.add_edge(*edge)\n            \n            # Compute the new community structure\n            communities = self.detection_alg.compute_community(graph)\n            new_community = Utils.get_new_community(\n                self.target_node, communities)\n\n            check = Utils.check_goal(\n                self.env, self.target_node, self.target_community, new_community)\n            if check == 1:\n                # If the target community is a subset of the new community, the episode is finished\n                done = True\n            self.steps -= 1\n            \n            self.steps -= 1\n        return graph, communities","metadata":{"id":"FzIcZjzQH27Q","execution":{"iopub.status.busy":"2023-09-20T08:40:47.886593Z","iopub.execute_input":"2023-09-20T08:40:47.886974Z","iopub.status.idle":"2023-09-20T08:40:47.901836Z","shell.execute_reply.started":"2023-09-20T08:40:47.886946Z","shell.execute_reply":"2023-09-20T08:40:47.900744Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"markdown","source":"#### Degree Hiding","metadata":{"id":"4heBBDFWIKmR"}},{"cell_type":"code","source":"class DegreeHiding():\n\n    def __init__(\n            self,\n            env,\n            steps: int,\n            target_community: List[int]):\n        self.env = env\n        self.graph = self.env.original_graph\n        self.steps = steps\n        self.target_node = self.env.node_target\n        self.target_community = target_community\n        self.detection_alg = self.env.detection\n        self.original_community_structure = self.env.original_community_structure\n        self.possible_edges = self.get_possible_action()  # self.env.possible_actions\n        # Put all the edges in a list\n        # self.possible_edges = self.env.possible_actions\n        # self.possible_edges = list(self.possible_edges[\"ADD\"]) + list(self.possible_edges[\"REMOVE\"])\n\n    def get_possible_action(self):\n        # Put all edge between the target node and its neighbors in a list\n        possible_actions_add = []\n        for neighbor in self.graph.neighbors(self.target_node):\n            possible_actions_add.append((self.target_node, neighbor))\n\n        # Put all the edges that aren't neighbors of the target node in a list\n        possible_actions_remove = []\n        for node in self.graph.nodes():\n            if node != self.target_node and node not in self.graph.neighbors(self.target_node):\n                possible_actions_remove.append((self.target_node, node))\n        possible_action = possible_actions_add + possible_actions_remove\n        return possible_action\n    \n    def hide_target_node_from_community(self) -> tuple:\n        \"\"\"\n        Hide the target node from the target community by rewiring its edges, \n        choosing the node with the highest degree between adding or removing an edge.\n        \n        Returns\n        -------\n        G_prime: nx.Graph\n        \"\"\"\n        graph = self.graph.copy()\n        done = False\n        # From the list possible_edges, create a list of tuples \n        # (node1, node2, degree_of_node2)\n        possible_edges = []\n        for edge in self.possible_edges:\n                possible_edges.append(\n                    (edge[0], edge[1], graph.degree(edge[1])))\n        while self.steps > 0 and not done:\n            # Choose the edge with the highest degree\n            max_tuple = max(possible_edges, key=lambda x: x[2])\n            possible_edges.remove(max_tuple)\n            edge = (max_tuple[0], max_tuple[1])\n            \n            if graph.has_edge(*edge):\n                # Remove the edge\n                graph.remove_edge(*edge)\n            else:\n                # Add the edge\n                graph.add_edge(*edge)\n\n            # Compute the new community structure\n            communities = self.detection_alg.compute_community(graph)\n            new_community = Utils.get_new_community(self.target_node, communities)\n\n            check = Utils.check_goal(self.env, self.target_node, self.target_community, new_community)\n            if check == 1:\n                # If the target community is a subset of the new community, the episode is finished\n                done = True\n            self.steps -= 1\n        return graph, communities","metadata":{"id":"Gv5y7U2xHyrI","execution":{"iopub.status.busy":"2023-09-20T08:40:47.904190Z","iopub.execute_input":"2023-09-20T08:40:47.904759Z","iopub.status.idle":"2023-09-20T08:40:47.920725Z","shell.execute_reply.started":"2023-09-20T08:40:47.904717Z","shell.execute_reply":"2023-09-20T08:40:47.919468Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"markdown","source":"#### Roam Hiding","metadata":{"id":"5yNPbm9gL8OI"}},{"cell_type":"code","source":"class RoamHiding():\n    \"\"\"Given a network and a source node v,our objective is to conceal the \n    importance of v by decreasing its centrality without compromising its\n    influence over the network.\n    \n    From the article \"Hiding Individuals and Communities in a Social Network\".\n    \"\"\"\n    def __init__(self, graph: nx.Graph, target_node: int, detection_alg: str) -> None:\n        self.graph = graph\n        self.target_node = target_node\n        self.detection_alg = CommunityDetectionAlgorithm(detection_alg)\n    \n    @staticmethod\n    def get_edge_budget(graph: nx.Graph, budget: float) -> int:\n        \"\"\"\n        Compute the number of edges to add given a budget and a graph.\n\n        Parameters\n        ----------\n        graph : nx.Graph\n            Graph to add edges to.\n        budget : int\n            Budget of the attack, value between 0 and 100.\n\n        Returns\n        -------\n        int\n            Number of edges to add.\n        \"\"\"\n        assert budget > 0 and budget <= 100, \"Budget must be between 0 and 100\"\n        return int(budget * graph.number_of_edges() / 100)\n    \n    def roam_heuristic(self, budget: int) -> tuple:\n        \"\"\"\n        The ROAM heuristic given a budget b:\n            - Step 1: Remove the link between the source node, v, and its \n            neighbour of choice, v0;\n            - Step 2: Connect v0 to b − 1 nodes of choice, who are neighbours \n            of v but not of v0 (if there are fewer than b − 1 such neighbours, \n            connect v0 to all of them).\n\n        Returns\n        -------\n        graph : nx.Graph\n            The graph after the ROAM heuristic.\n        \"\"\"\n        edge_budget = self.get_edge_budget(self.graph, budget)\n        \n        # ° --- Step 1 --- ° #\n        target_node_neighbours = list(self.graph.neighbors(self.target_node))\n        \n        # Choose v0 as the neighbour of target_node with the most connections\n        v0 = target_node_neighbours[0]\n        for v in target_node_neighbours:\n            if self.graph.degree[v] > self.graph.degree[v0]:\n                v0 = v\n        # v0 = random.choice(target_node_neighbours)    # Random choice\n        # Remove the edge between v and v0\n        self.graph.remove_edge(self.target_node, v0)\n        \n        # ° --- Step 2 --- ° #\n        # Get the neighbours of v0\n        v0_neighbours = list(self.graph.neighbors(v0))\n        # Get the neighbours of v, who are not neighbours of v0\n        v_neighbours_not_v0 = [x for x in target_node_neighbours if x not in v0_neighbours]\n        # If there are fewer than b-1 such neighbours, connect v_0 to all of them\n        if len(v_neighbours_not_v0) < edge_budget-1:\n            edge_budget = len(v_neighbours_not_v0) + 1\n        # Make an ascending order list of the neighbours of v0, based on their degree\n        sorted_neighbors = sorted(v_neighbours_not_v0, key=lambda x: self.graph.degree[x]) \n        # Connect v_0 to b-1 nodes of choice, who are neighbours of v but not of v_0\n        for i in range(edge_budget-1):\n            v0_neighbour = sorted_neighbors[i]\n            # v0_neighbour = random.choice(v_neighbours_not_v0)   # Random choice\n            self.graph.add_edge(v0, v0_neighbour)\n            v_neighbours_not_v0.remove(v0_neighbour)\n        \n        new_community_structure = self.detection_alg.compute_community(self.graph)\n        return self.graph, new_community_structure","metadata":{"id":"uWP6CX_XL-oc","execution":{"iopub.status.busy":"2023-09-20T08:40:47.922304Z","iopub.execute_input":"2023-09-20T08:40:47.922694Z","iopub.status.idle":"2023-09-20T08:40:47.939850Z","shell.execute_reply.started":"2023-09-20T08:40:47.922658Z","shell.execute_reply":"2023-09-20T08:40:47.937966Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"markdown","source":"## Similarity Metrics","metadata":{"id":"9o-92qV6HfNW"}},{"cell_type":"code","source":"class CommunitySimilarity():\n    \"\"\"Class to compute the similarity between two lists of integers\"\"\"\n    def __init__(self, function_name: str) -> None:\n        self.function_name = function_name\n\n    def select_similarity_function(self) -> Callable:\n        \"\"\"\n        Select the similarity function to use\n\n        Returns\n        -------\n        Callable\n            Similarity function to use\n        \"\"\"\n        if self.function_name == SimilarityFunctionsNames.JAC.value:\n            return self.jaccard_similarity\n        elif self.function_name == SimilarityFunctionsNames.OVE.value:\n            return self.overlap_similarity\n        elif self.function_name == SimilarityFunctionsNames.SOR.value:\n            return self.sorensen_similarity\n        else:\n            raise Exception(\"Similarity function not found\")\n\n    @staticmethod\n    def jaccard_similarity(a: List[int], b: List[int]) -> float:\n        \"\"\"\n        Compute the Jaccard similarity between two lists, A and B:\n            J(A,B) = |A ∩ B| / |A U B|\n\n        Parameters\n        ----------\n        a : List[int]\n            First List\n        b : List[int]\n            Second List\n\n        Returns\n        -------\n        float\n            Jaccard similarity between the two lists, between 0 and 1\n        \"\"\"\n        assert len(a) > 0 and len(b) > 0, \"Lists must be not empty\"\n        # Convert lists to sets\n        a_set = set(a)\n        b_set = set(b)\n        # Compute the intersection and union\n        intersection = a_set.intersection(b_set)\n        union = a_set.union(b_set)\n        return len(intersection) / len(union)\n\n    @staticmethod\n    def overlap_similarity(a: List[int], b: List[int]) -> float:\n        \"\"\"\n        Compute the Overlap similarity between two lists, A and B:\n            O(A,B) = |A ∩ B| / min(|A|, |B|)\n\n        Parameters\n        ----------\n        a : List[int]\n            First List\n        b : List[int]\n            Fist List\n\n        Returns\n        -------\n        float\n            Overlap coefficient between the two lists, value between 0 and 1\n        \"\"\"\n        assert len(a) > 0 and len(b) > 0, \"Lists must be not empty\"\n        # Convert lists to sets\n        a_set = set(a)\n        b_set = set(b)\n        # Compute the intersection\n        intersection = a_set.intersection(b_set)\n        return len(intersection) / min(len(a_set), len(b_set))\n\n    @staticmethod\n    def sorensen_similarity(a: List[int], b: List[int]) -> float:\n        \"\"\"\n        Compute the Sorensen similarity between two lists, A and B:\n            S(A,B) = 2 * |A ∩ B| / (|A| + |B|)\n\n        Parameters\n        ----------\n        a : List[int]\n            First List\n        b : List[int]\n            Second List\n\n        Returns\n        -------\n        float\n            Sorensen similarity between the two lists, between 0 and 1\n        \"\"\"\n        assert len(a) > 0 and len(b) > 0, \"Lists must be not empty\"\n        # Convert lists to sets\n        a_set = set(a)\n        b_set = set(b)\n        # Compute the intersection\n        intersection = a_set.intersection(b_set)\n        return 2 * len(intersection) / (len(a_set) + len(b_set))\n\n\nclass GraphSimilarity():\n    \"\"\"Class to compute the similarity between two graphs\"\"\"\n    def __init__(self, function_name: str) -> None:\n        \"\"\"\n        Initialize the GraphSimilarity class\n\n        Parameters\n        ----------\n        function_name : str\n            Name of the similarity function to use\n        \"\"\"\n        self.function_name = function_name\n\n    def select_similarity_function(self) -> Callable:\n        \"\"\"\n        Select the similarity function to use\n\n        Returns\n        -------\n        Callable\n            Similarity function to use\n        \"\"\"\n        if self.function_name == SimilarityFunctionsNames.GED.value:\n            return self.graph_edit_distance\n        elif self.function_name == SimilarityFunctionsNames.JAC_1.value:\n            return self.jaccard_similarity_1\n        elif self.function_name == SimilarityFunctionsNames.JAC_2.value:\n            return self.jaccard_similarity_2\n        else:\n            raise Exception(\"Similarity function not found\")\n\n    def graph_edit_distance(self, g: nx.Graph, h: nx.Graph) -> float:\n        \"\"\"\n        Compute the graph edit distance between two graphs, then normalize it\n        using a null graph:\n            GED(G1,G2)/[GED(G1,G0) + GED(G2,G0)]  with G0 = null graph\n\n        Parameters\n        ----------\n        g : nx.Graph\n            First graph\n        h : nx.Graph\n            Second graph\n\n        Returns\n        -------\n        graph_distance : float\n            Graph edit distance between the two graphs normalized\n        \"\"\"\n        # Slow, but precise\n        # graph_distance = nx.graph_edit_distance(self.graph, self.old_graph)\n\n        # Faster approximation of the graph edit distance\n        graph_distance = next(nx.optimize_graph_edit_distance(g, h))\n        # Normalize\n        g_dist_1 = next(nx.optimize_graph_edit_distance(g, nx.null_graph()))\n        g_dist_2 = next(nx.optimize_graph_edit_distance(h, nx.null_graph()))\n        graph_distance /= (g_dist_1 + g_dist_2)\n        return graph_distance\n\n    def jaccard_similarity_1(self, g: nx.Graph, h: nx.Graph) -> float:\n        \"\"\"\n        Compute the Jaccard Similarity between two graphs\n        J(G, H) = (∑_{i,j} |A_{ij}^G - A_{i,j}^H|) / (∑_{i,j} max(A_{i,j)^G, A_{i,j}^H))\n\n        Parameters\n        ----------\n        g : nx.Graph\n            First graph\n        h : nx.Graph\n            Second graph\n\n        Returns\n        -------\n        jaccard_sim : float\n            Jaccard Similarity between the two graphs, between 0 and 1,\n            where 0 means the two graphs are identical and 1 means they are\n            completely different\n        \"\"\"\n        # Get adjacency matrices\n        g_matrix = nx.to_numpy_array(g)\n        h_matrix = nx.to_numpy_array(h)\n        # Ensure G and H have the same shape\n        if g_matrix.shape != h_matrix.shape:\n            raise ValueError(\"Input matrices must have the same shape.\")\n        # Calculate the numerator (sum of absolute differences)\n        numerator = np.sum(np.abs(g_matrix - h_matrix))\n        # Calculate the denominator (sum of element-wise maximum values)\n        denominator = np.sum(np.maximum(g_matrix, h_matrix))\n        # Calculate the Jaccard similarity\n        jaccard_sim = numerator / denominator\n        return jaccard_sim\n\n    def jaccard_similarity_2(self, g: nx.Graph, h: nx.Graph) -> float:\n        \"\"\"\n        Compute the Jaccard Similarity between two graphs, second version\n\n        Parameters\n        ----------\n        g : nx.Graph\n            First graph\n        h : nx.Graph\n            Second graph\n\n        Returns\n        -------\n        float\n            jaccard similarity between the two graphs\n        \"\"\"\n        g = g.edges()\n        h = h.edges()\n        i = set(g).intersection(h)\n        j = round(len(i) / (len(g) + len(h) - len(i)), 3)\n        # Normalize to have 0 if the graphs are identical and 1 if they are\n        # completely different\n        return 1-j\n","metadata":{"id":"aUCei7YWHhtl","execution":{"iopub.status.busy":"2023-09-20T08:40:47.941811Z","iopub.execute_input":"2023-09-20T08:40:47.942874Z","iopub.status.idle":"2023-09-20T08:40:47.972944Z","shell.execute_reply.started":"2023-09-20T08:40:47.942836Z","shell.execute_reply":"2023-09-20T08:40:47.971905Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"markdown","source":"## Enviroment","metadata":{"_cell_guid":"ceeaedf8-6720-420a-b65e-d06a50c808b6","_uuid":"4c7613d9-d95e-4eb0-b9d1-8d95928c459f","id":"-l6FamFa4qN2","trusted":true}},{"cell_type":"code","source":"class GraphEnvironment(object):\n    \"\"\"Enviroment where the agent will act, it will be a graph with a community\"\"\"\n\n    def __init__(\n        self,\n        graph_path: str = HyperParams.GRAPH_NAME.value,\n        community_detection_algorithm: str = HyperParams.DETECTION_ALG_NAME.value,\n        beta: float = HyperParams.BETA.value,\n        tau: float = HyperParams.TAU.value,\n        community_similarity_function: str = SimilarityFunctionsNames.SOR.value,\n        graph_similarity_function: str = SimilarityFunctionsNames.JAC_1.value,\n    ) -> None:\n        \"\"\"Constructor for Graph Environment\n        Parameters\n        ----------\n        graph_path : str, optional\n            Path of the graph to load, by default HyperParams.GRAPH_NAME.value\n        community_detection_algorithm : str\n            Name of the community detection algorithm to use\n        beta : float, optional\n            Percentage of edges to remove, by default HyperParams.BETA.value\n        tau : float, optional\n            Strength of the deception constraint, value between 0 and 1, with 1\n            we have a soft constraint, hard constraint otherwise, by default\n            HyperParams.T.value\n        community_similarity_function : str, optional\n            Name of the community similarity function to use, by default\n            SimilarityFunctionsNames.SOR.value\n        graph_similarity_function : str, optional\n            Name of the graph similarity function to use, by default\n            SimilarityFunctionsNames.JAC_1.value\n        \"\"\"\n        random.seed(time.time())\n        self.device = torch.device(\n            'cuda:0' if torch.cuda.is_available() else 'cpu')\n        # ° ---- GRAPH ---- ° #\n        # Load the graph from the dataset folder\n        if graph_path is None:\n            # Generate a synthetic graph\n            self.graph, graph_path = Utils.generate_lfr_benchmark_graph()\n        else:\n            self.graph = Utils.import_mtx_graph(graph_path)\n\n        # For each node, add a feature vector named \"x\" with value a tensor\n        # of dimension equal to 2, with the first value equal to the node id\n        # and the second value equal to the negative node id\n        for i, node in enumerate(self.graph.nodes()):\n            self.graph.nodes[node][\"x\"] = [float(i), float(-i)]\n            # Similar version with a one-hot encoding tensor\n            # BUG: The size of the network using one-hot is too big, it does not fit in kaggle memory\n            # self.graph.nodes[node][\"x\"] = torch.zeros(self.graph.number_of_nodes())\n            # self.graph.nodes[node][\"x\"][node] = 1\n\n        # Save the original graph to restart the rewiring process at each episode\n        self.original_graph = self.graph.copy()\n        # Save the graph state before the action, used to compute the metrics\n        self.old_graph = None\n        # Get the Number of connected components\n        self.n_connected_components = nx.number_connected_components(\n            self.graph)\n\n        # ° ---- HYPERPARAMETERS ---- ° #\n        assert beta >= 0 and beta <= 100, \"Beta must be between 0 and 100\"\n        assert tau >= 0 and tau <= 1, \"T value must be between 0 and 1\"\n        # Percentage of edges to remove\n        self.beta = beta\n        self.tau = tau\n        # Weights for the reward and the penalty\n        self.lambda_metric = None  # lambda_metric\n        self.alpha_metric = None  # alpha_metric\n\n        # ° ---- SIMILARITY FUNCTIONS ---- ° #\n        # Select the similarity function to use to compare the communities\n        self.community_similarity = CommunitySimilarity(\n            community_similarity_function).select_similarity_function()\n        self.graph_similarity = GraphSimilarity(\n            graph_similarity_function).select_similarity_function()\n\n        # ° ---- COMMUNITY DETECTION ---- ° #\n        # Name of the environment and the community detection algorithm\n        self.env_name = graph_path.split(\"/\")[-1].split(\".\")[0]\n        self.detection_alg = community_detection_algorithm\n        # Community Algorithms objects\n        self.detection = CommunityDetectionAlgorithm(\n            community_detection_algorithm)\n        # Metrics\n        self.old_penalty_value = 0\n        # Compute the community structure of the graph, before the action,\n        # i.e. before the deception\n        self.original_community_structure = self.detection.compute_community(\n            self.graph)\n        # ! It is a NodeClustering object\n        self.old_community_structure = self.original_community_structure\n        self.new_community_structure = None\n\n        # ° ---- COMMUNITY DECEPTION ---- ° #\n        # Choose one of the communities found by the algorithm, as initial\n        # community we choose the community with the highest number of nodes\n        self.community_target = max(\n            self.original_community_structure.communities, key=len)\n        if len(self.community_target) <= 1:\n            raise Exception(\"Community target must have at least two node.\")\n\n        # Choose a node randomly from the community, as initial node to remove\n        self.node_target = random.choice(self.community_target)\n\n        # ° ---- REWIRING STEP ---- ° #\n        # Compute the edge budget for the graph, i.e. the mean degree of the \n        # graph times the parameter beta\n        self.edge_budget = self.get_edge_budget() * self.beta\n        # Amount of budget used\n        self.used_edge_budget = 0\n        # Max Rewiring Steps during an episode, set a limit to avoid infinite \n        # episodes in case the agent does not find the target node\n        self.max_steps = self.edge_budget * HyperParams.MAX_STEPS_MUL.value\n        # Whether the budget for the graph rewiring is exhausted, or the target\n        # node does not belong to the community anymore\n        self.stop_episode = False\n        self.rewards = 0\n        # Reward of the previous step\n        self.old_rewards = 0\n        # Compute the set of possible actions\n        self.possible_actions = self.get_possible_actions()\n        # Length of the list of possible actions to add\n        self.len_add_actions = len(self.possible_actions[\"ADD\"])\n\n        # ° ---- PRINT ENVIRONMENT INFO ---- ° #\n        # Print the environment information\n        self.print_env_info()\n\n    ############################################################################\n    #                       GETTERS FUNCTIONS                                  #\n    ############################################################################\n\n    def get_edge_budget(self) -> int:\n        \"\"\"\n        Computes the edge budget for each graph\n\n        Returns\n        -------\n        int\n            Edge budgets of the graph\n        \"\"\"\n        # Get the mean degree of the graph\n        return int(self.graph.number_of_edges() / self.graph.number_of_nodes())\n        # return int(math.ceil((self.graph.number_of_edges() * self.beta / 100)))\n\n    def get_penalty(self) -> float:\n        \"\"\"\n        Compute the metrics and return the penalty to subtract from the reward\n\n        Returns\n        -------\n        penalty: float\n            Penalty to subtract from the reward\n        \"\"\"\n        # ° ---- COMMUNITY DISTANCE ---- ° #\n        community_distance = self.new_community_structure.normalized_mutual_information(\n            self.old_community_structure).score\n        # In NMI 1 means that the two community structures are identical,\n        # 0 means that they are completely different\n        # We want to maximize the NMI, so we subtract it from 1\n        community_distance = 1 - community_distance\n        # ° ---- GRAPH DISTANCE ---- ° #\n        graph_distance = self.graph_similarity(self.graph, self.old_graph)\n        # ° ---- PENALTY ---- ° #\n        assert self.alpha_metric is not None, \"Alpha metric is None, must be set in grid search\"\n        penalty = self.alpha_metric * community_distance + \\\n            (1 - self.alpha_metric) * graph_distance\n        # Subtract the metric value of the previous step\n        penalty -= self.old_penalty_value\n        # Update with the new values\n        self.old_penalty_value = penalty\n        return penalty\n\n    def get_reward(self) -> Tuple[float, bool]:\n        \"\"\"\n        Computes the reward for the agent, it is a 0-1 value function, if the\n        target node still belongs to the community, the reward is 0 minus the\n        penalty, otherwise the reward is 1 minus the penalty.\n\n        As new community target after the action, we consider the community\n        that contains the target node, if this community satisfies the deception\n        constraint, the episode is finished, otherwise not.\n\n        Returns\n        -------\n        reward : float\n            Reward of the agent\n        done : bool\n            Whether the episode is finished, if the target node does not belong\n            to the community anymore, the episode is finished\n        \"\"\"\n        assert self.lambda_metric is not None, \"Lambda metric is None, must be set in grid search\"\n        # Get the target community in the new community structure that\n        # contains the target node\n        for community in self.new_community_structure.communities:\n            if self.node_target in community:\n                new_community_target = community\n                break\n        assert new_community_target is not None, \"New community target is None\"\n        # ° ---------- PENALTY ---------- ° #\n        # Compute the metric to subtract from the reward\n        penalty = self.get_penalty()\n        # If the target node does not belong to the community anymore,\n        # the episode is finished\n        if len(new_community_target) == 1:\n            reward = 1 - (self.lambda_metric * penalty)\n            return reward, True\n        # ° ---- COMMUNITY SIMILARITY ---- ° #\n        # Remove target node from the communities, but first copy the lists\n        # to avoid modifying them\n        new_community_target_copy = new_community_target.copy()\n        new_community_target_copy.remove(self.node_target)\n        community_target_copy = self.community_target.copy()\n        community_target_copy.remove(self.node_target)\n        # Compute the similarity between the new communities\n        community_similarity = self.community_similarity(\n            new_community_target_copy,\n            community_target_copy,\n        )\n        # Delete the copies\n        del new_community_target_copy, community_target_copy\n        # ° ---------- REWARD ---------- ° #\n        if community_similarity <= self.tau:\n            # We have reached the deception constraint, the episode is finished\n            reward = 1 - (self.lambda_metric * penalty)\n            return reward, True\n        reward = 0 - (self.lambda_metric * penalty)\n        return reward, False\n\n    def get_possible_actions(self) -> dict:\n        \"\"\"\n        Returns all the possible actions that can be applied to the graph\n        given a source node (self.node_target). The possible actions are:\n            - Add an edge between the source node and a node outside the community\n            - Remove an edge between the source node and a node inside the community\n\n        Returns\n        -------\n        self.possible_actions : dict\n            Dictionary containing the possible actions that can be applied to\n            the graph. The dictionary has two keys: \"ADD\" and \"REMOVE\", each\n            key has a list of tuples as value, where each tuple is an action.\n        \"\"\"\n        possible_actions = {\"ADD\": set(), \"REMOVE\": set()}\n        # Helper functions to check if a node is in/out-side the community\n\n        def in_community(node):\n            return node in self.community_target\n\n        def out_community(node):\n            return node not in self.community_target\n\n        u = self.node_target\n        for v in self.graph.nodes():\n            if u == v:\n                continue\n            # We can remove an edge iff both nodes are in the community\n            if in_community(u) and in_community(v):\n                if self.graph.has_edge(u, v):\n                    if (v, u) not in possible_actions[\"REMOVE\"]:\n                        possible_actions[\"REMOVE\"].add((u, v))\n            # We can add an edge iff one node is in the community and the other is not\n            elif (in_community(u) and out_community(v)) \\\n                    or (out_community(u) and in_community(v)):\n                # Check if there is already an edge between the two nodes\n                if not self.graph.has_edge(u, v):\n                    if (v, u) not in possible_actions[\"ADD\"]:\n                        possible_actions[\"ADD\"].add((u, v))\n        return possible_actions\n\n    ############################################################################\n    #                       EPISODE RESET FUNCTIONS                            #\n    ############################################################################\n\n    def reset(self) -> nx.Graph:\n        \"\"\"\n        Reset the environment\n\n        Returns\n        -------\n        self.graph : nx.Graph\n            Graph state after the reset, i.e. the original graph\n        \"\"\"\n        self.used_edge_budget = 0\n        self.stop_episode = False\n        self.rewards = 0\n        self.old_rewards = 0\n        self.graph = self.original_graph.copy()\n        self.old_graph = None\n        self.old_penalty_value = 0\n        self.old_community_structure = self.original_community_structure\n        self.possible_actions = self.get_possible_actions()\n        return self.graph\n\n    def change_target_node(self, node_target: int = None) -> None:\n        \"\"\"\n        Change the target node to remove from the community\n\n        Parameters\n        ----------\n        node_target : int, optional\n            Node to remove from the community, by default None\n        \"\"\"\n        if node_target is None:\n            # Choose a node randomly from the community\n            old_node = self.node_target\n            while self.node_target == old_node:\n                random.seed(time.time())\n                self.node_target = random.choice(self.community_target)\n        else:\n            self.node_target = node_target\n\n    def change_target_community(\n            self,\n            community: List[int] = None,\n            node_target: int = None) -> None:\n        \"\"\"\n        Change the target community from which we want to hide the node\n\n        Parameters\n        ----------\n        community : List[int]\n            Community of node we want to remove from it\n        node_target : int\n            Node to remove from the community\n        \"\"\"\n        if community is None:\n            # Select randomly a new community target different from the last one\n            old_community = self.community_target.copy()\n            done = False\n            while not done:\n                random.seed(time.time())\n                self.community_target = random.choice(\n                    self.original_community_structure.communities)\n                # Check condition on new community\n                if (len(self.community_target) > 1 and \\\n                        self.community_target != old_community) or \\\n                            len(self.original_community_structure.communities) < 2:\n                    done = True\n            del old_community\n        else:\n            self.community_target = community\n        # Change the target node to remove from the community\n        self.change_target_node(node_target=node_target)\n\n    ############################################################################\n    #                      EPISODE STEP FUNCTIONS                              #\n    ############################################################################\n    def step(self, action: int) -> Tuple[nx.Graph, float, bool, bool]:\n        \"\"\"\n        Step function for the environment\n\n        Parameters\n        ----------\n        action : int\n            Integer representing a node in the graph, it will be the destination\n            node of the rewiring action (out source node is always the target node).\n\n        Returns\n        -------\n        self.graph : nx.Graph\n            Graph state after the action\n        self.rewards : float\n            Reward of the agent\n        self.stop_episode : bool\n            If the budget for the graph rewiring is exhausted, or the target\n            node does not belong to the community anymore, the episode is finished\n        done : bool\n            Whether the episode is finished, if the target node does not belong\n            to the community anymore, the episode is finished.\n        \"\"\"\n        # ° ---- ACTION ---- ° #\n        # Save the graph state before the action, used to compute the metrics\n        self.old_graph = self.graph.copy()\n        # Take action, add/remove the edge between target node and the model output\n        budget_consumed = self.apply_action(action)\n        # Set a negative reward if the action has not been applied\n        if budget_consumed == 0:\n            self.rewards = -1\n            # The state is the same as before\n            # return self.data_pyg, self.rewards, self.stop_episode\n            return self.graph, self.rewards, self.stop_episode, False\n\n        # ° ---- COMMUNITY DETECTION ---- ° #\n        # Compute the community structure of the graph after the action\n        self.new_community_structure = self.detection.compute_community(\n            self.graph)\n\n        # ° ---- REWARD ---- ° #\n        self.rewards, done = self.get_reward()\n        # If the target node does not belong to the community anymore,\n        # the episode is finished\n        if done:\n            self.stop_episode = True\n\n        # ° ---- BUDGET ---- ° #\n        # Compute used budget\n        self.used_edge_budget += budget_consumed\n        # If the budget for the graph rewiring is exhausted, stop the episode\n        if self.edge_budget - self.used_edge_budget < 1:\n            self.stop_episode = True\n            # If the budget is exhausted, and the target node still belongs to\n            # the community, the reward is negative\n            # if not done:\n            #    self.rewards = -2\n\n        self.old_community_structure = self.new_community_structure\n        return self.graph, self.rewards, self.stop_episode, done\n\n    def apply_action(self, action: int) -> int:\n        \"\"\"\n        Applies the action to the graph, if there is an edge between the two\n        nodes, it removes it, otherwise it adds it\n\n        Parameters\n        ----------\n        action : int\n            Integer representing a node in the graph, it will be the destination\n            node of the rewiring action (out source node is always the target node).\n\n        Returns\n        -------\n        budget_consumed : int\n            Amount of budget consumed, 1 if the action has been applied, 0 otherwise\n        \"\"\"\n        action = (self.node_target, action)\n        # We need to take into account both the actions (u,v) and (v,u)\n        action_reversed = (action[1], action[0])\n        if action in self.possible_actions[\"ADD\"]:\n            self.graph.add_edge(*action, weight=1)\n            self.possible_actions[\"ADD\"].remove(action)\n            return 1\n        elif action_reversed in self.possible_actions[\"ADD\"]:\n            self.graph.add_edge(*action_reversed, weight=1)\n            self.possible_actions[\"ADD\"].remove(action_reversed)\n            return 1\n        elif action in self.possible_actions[\"REMOVE\"]:\n            self.graph.remove_edge(*action)\n            self.possible_actions[\"REMOVE\"].remove(action)\n            return 1\n        elif action_reversed in self.possible_actions[\"REMOVE\"]:\n            self.graph.remove_edge(*action_reversed)\n            self.possible_actions[\"REMOVE\"].remove(action_reversed)\n            return 1\n        return 0\n\n    ############################################################################\n    #                           ENVIRONMENT INFO                               #\n    ############################################################################\n    def print_env_info(self) -> None:\n        \"\"\"Print the environment information\"\"\"\n        print(\"*\"*20, \"Environment Information\", \"*\"*20)\n        print(\"* Graph Name:\", self.env_name)\n        print(\"*\", self.graph)\n        print(\"* Community Detection Algorithm:\", self.detection_alg)\n        print(\"* Number of communities found:\",\n              len(self.original_community_structure.communities))\n        # print(\"* Rewiring Budget:\", self.edge_budget, \"=\", self.beta, \"*\", self.graph.number_of_edges(), \"/ 100\",)\n        print(\"* Rewiring Budget: (Number of Nodes / Number of Edges) * BETA =\",\n              self.graph.number_of_nodes(), \"/\",\n              self.graph.number_of_edges(), \"*\", self.beta, \"=\",\n              int(self.graph.number_of_edges() / self.graph.number_of_nodes())*self.beta)\n        print(\"* Weight of the Deception Constraint:\", self.tau)\n        print(\"*\", \"-\"*58, \"\\n\")","metadata":{"_cell_guid":"1fdc6a76-c3f9-4504-876f-1764509417cd","_uuid":"3ebe6bed-0762-40d3-bbab-e47dcb6e671f","collapsed":false,"id":"iQDrQKvy4qN2","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-20T08:40:47.978430Z","iopub.execute_input":"2023-09-20T08:40:47.978795Z","iopub.status.idle":"2023-09-20T08:40:48.045956Z","shell.execute_reply.started":"2023-09-20T08:40:47.978745Z","shell.execute_reply":"2023-09-20T08:40:48.044886Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"markdown","source":"## Agent","metadata":{"_cell_guid":"f8573615-d7f2-4746-9a63-89c8f4f22b58","_uuid":"ffc24ac0-b9c6-4aca-9f60-df397d18451f","id":"vAdiThYJ4qN3","trusted":true}},{"cell_type":"code","source":"class Agent:\n    def __init__(\n        self,\n        env: GraphEnvironment,\n        state_dim: int = HyperParams.EMBEDDING_DIM.value,\n        hidden_size_1: int = HyperParams.HIDDEN_SIZE_1.value,\n        hidden_size_2: int = HyperParams.HIDDEN_SIZE_2.value,\n        lr: List[float] = HyperParams.LR.value,\n        gamma: List[float] = HyperParams.GAMMA.value,\n        lambda_metrics: List[float] = HyperParams.LAMBDA.value,\n        alpha_metrics: List[float] = HyperParams.ALPHA.value,\n        eps: float = HyperParams.EPS_CLIP.value,\n        best_reward: float = HyperParams.BEST_REWARD.value):\n        \"\"\"\n        Initialize the agent.\n\n        Parameters\n        ----------\n        env : GraphEnvironment\n            Environment to train the agent on\n        state_dim : int\n            Dimensions of the state, i.e. length of the feature vector\n        hidden_size_1 : int\n            First A2C hidden layer size\n        hidden_size_2 : int\n            Second A2C hidden layer size\n        action_dim : int\n            Dimensions of the action (it is set to 1, to return a tensor N*1)\n        lr : List[float]\n            List of Learning rate, each element of the list is a learning rate\n        gamma : List[float]\n            List of gamma parameter, each element of the list is a gamma\n        lambda_metrics : List[float]\n            List of lambda parameter, each element of the list is a lambda used\n            to balance the reward and the penalty\n        alpha_metrics : List[float]\n            List of alpha parameter, each element of the list is a alpha used\n            to balance the two penalties\n        eps : List[float]\n            Value for clipping the loss function, each element of the list is a\n            clipping value\n        best_reward : float, optional\n            Best reward, by default 0.8\n        \"\"\"\n        # ° ----- Environment ----- ° #\n        self.env = env\n\n        # ° ----- A2C ----- ° #\n        self.state_dim = 2  # state_dim # self.env.graph.number_of_nodes()\n        self.hidden_size_1 = hidden_size_1\n        self.hidden_size_2 = hidden_size_2\n        self.action_dim = self.env.graph.number_of_nodes()\n        self.policy = ActorCritic(\n            state_dim=self.state_dim,\n            hidden_size_1=self.hidden_size_1,\n            hidden_size_2=self.hidden_size_2,\n            action_dim=self.action_dim,\n            graph=self.env.graph\n        )\n        # Set device\n        self.device = torch.device(\n            'cuda:0' if torch.cuda.is_available() else 'cpu')\n        # Move model to device\n        self.policy.to(self.device)\n\n        # ° ----- Hyperparameters ----- ° #\n        # A2C hyperparameters\n        self.lr_list = lr\n        self.gamma_list = gamma\n        self.eps = eps\n        self.best_reward = best_reward\n        # Environment hyperparameters\n        self.lambda_metrics = lambda_metrics\n        self.alpha_metrics = alpha_metrics\n        # Hyperparameters to be set during grid search\n        self.lr = None\n        self.gamma = None\n        self.alpha_metric = None\n        self. optimizers = dict()\n\n        # ° ----- Training ----- ° #\n        # State, nx.Graph\n        self.obs = None\n        # Cumulative reward of the episode\n        self.episode_reward = 0\n        # Boolean variable to check if the episode is ended\n        self.done = False\n        # Boolean variable to check if the goal is reached\n        self.goal = False\n        # Number of steps in the episode\n        self.step = 0\n        # Tuple to store the values for each action\n        self.SavedAction = namedtuple('SavedAction', ['log_prob', 'value'])\n        self.saved_actions = []\n        self.rewards = []\n        # List of rewards for one episode\n        self.episode_rewards = []\n        # Initialize lists for logging, it contains: avg_reward, avg_steps per episode\n        self.log_dict = HyperParams.LOG_DICT.value\n        # Print agent info\n        self.print_agent_info()\n\n        # ° ----- Evaluation ----- ° #\n        # List of actions performed during the evaluation\n        self.action_list = {\"ADD\": [], \"REMOVE\": []}\n\n    ############################################################################\n    #                       PRE-TRAINING/TESTING                               #\n    ############################################################################\n    def reset_hyperparams(\n            self,\n            lr: float,\n            gamma: float,\n            lambda_metric: float,\n            alpha_metric: float,\n            test: bool = False) -> None:\n        \"\"\"\n        Reset hyperparameters\n        \n        Parameters\n        ----------\n        lr : float\n            Learning rate\n        gamma : float\n            Discount factor\n        lambda_metric : float\n            Lambda parameter used to balance the reward and the penalty\n        alpha_metric : float\n            Alpha parameter used to balance the two penalties\n        test : bool, optional\n            Print hyperparameters during training, by default False\n        \"\"\"\n        # Set A2C hyperparameters\n        self.lr = lr\n        self.gamma = gamma\n        # Set environment hyperparameters\n        self.env.lambda_metric = lambda_metric\n        self.env.alpha_metric = alpha_metric\n        # Print hyperparameters if we are not testing\n        if not test:\n            self.print_hyperparams()\n        # Clear logs, except for the training episodes\n        for key in self.log_dict.keys():\n            if key != 'train_episodes':\n                self.log_dict[key] = list()\n        # Clear action list\n        self.saved_actions = []\n        self.rewards = []\n        self.episode_rewards = []\n        # Clear state\n        self.obs = None\n        self.episode_reward = 0\n        self.done = False\n        self.goal = False\n        self.step = 0\n        self.optimizers = dict()\n\n    def configure_optimizers(self) -> None:\n        \"\"\"\n        Configure optimizers\n        \n        Returns\n        -------\n        optimizers : dict\n            Dictionary of optimizers\n        \"\"\"\n        actor_params = list(self.policy.actor.parameters())\n        critic_params = list(self.policy.critic.parameters())\n        self.optimizers['a_optimizer'] = torch.optim.Adam(\n            actor_params, lr=self.lr)\n        self.optimizers['c_optimizer'] = torch.optim.Adam(\n            critic_params, lr=self.lr)\n\n    ############################################################################\n    #                            GRID SEARCH                                   #\n    ############################################################################\n    def grid_search(self) -> None:\n        \"\"\"Perform grid search on the hyperparameters\"\"\"\n        for lr in self.lr_list:\n            for gamma in self.gamma_list:\n                for lambda_metric in self.lambda_metrics:\n                    for alpha_metric in self.alpha_metrics:\n                        # Change Hyperparameters\n                        self.reset_hyperparams(\n                            lr, gamma, lambda_metric, alpha_metric)\n                        # Configure optimizers with the current learning rate\n                        self.configure_optimizers()\n                        # Training\n                        log = self.training()\n                        # Save results in correct folder\n                        self.save_plots(log, self.get_path())\n                        # Free memory\n                        gc.collect()\n\n    ############################################################################\n    #                               TRAINING                                   #\n    ############################################################################\n    def training(self) -> dict:\n        \"\"\"\n        Train the agent on the environment, change the target node every 10\n        episodes and the target community every 100 episodes. The episode ends\n        when the target node is isolated from the target community, or when the\n        maximum number of steps is reached.\n            \n        Returns\n        -------\n        log_dict : dict\n            Dictionary containing the training logs\n        \"\"\"\n        episode = self.log_dict['train_episodes']\n        epochs = trange(episode)  # epoch iterator\n        self.policy.train()  # set model in train mode\n        for i_episode in epochs:\n            # Change target community and target node\n            self.env.change_target_community()\n\n            # Reset environment, original graph, and new set of possible actions\n            self.obs = self.env.reset()\n            self.episode_reward = 0\n            self.done = False\n            self.goal = False\n            self.episode_rewards = []\n            self.step = 0\n            \n            # Rewiring the graph until the target node is isolated from the\n            # target community\n            while not self.done and self.step < self.env.max_steps:\n                self.rewiring()\n                \n            # perform on-policy backpropagation\n            self.a_loss, self.v_loss = self.training_step()\n            \n            # Checkpoint best performing model\n            if self.episode_reward / self.step >= self.best_reward:\n                self.save_checkpoint(best=True)\n                self.best_reward = self.episode_reward\n\n            # Save model every 100 episodes\n            if i_episode % 10 == 0:\n                self.save_checkpoint(best=False)\n                \n            # ° Log\n            # Get the list of reward of the last self.step steps\n            rewards = self.episode_rewards[-self.step:]\n            # If the goal is reached, multiply the last reward by 10\n            if self.goal:\n                rewards[-1] *= 10\n            self.log_dict['train_reward_list'].append(rewards)\n            self.log_dict['train_reward_mul'].append(sum(rewards)/len(rewards))\n\n            self.log_dict['train_reward'].append(self.episode_reward)\n            self.log_dict['train_steps'].append(self.step)\n            self.log_dict['train_avg_reward'].append(\n                self.episode_reward/self.step)\n            self.log_dict['a_loss'].append(self.a_loss)\n            self.log_dict['v_loss'].append(self.v_loss)\n\n            # Send current statistics to screen\n            epochs.set_description(\n                f\"* Episode {i_episode+1} \" +\n                f\"| Mul Reward: {sum(rewards)/len(rewards):.2f}\"\n                f\"| Avg Reward: {self.episode_reward/self.step:.2f} \" +\n                f\"| Steps: {self.step} \" +\n                f\"| Actor Loss: {self.a_loss:.2f} \" +\n                f\"| Critic Loss: {self.v_loss:.2f}\")\n            del rewards\n        return self.log_dict\n\n    def rewiring(self, test=False) -> None:\n        \"\"\"\n        Rewiring step, select action and take step in environment.\n        \n        Parameters\n        ----------\n        test : bool, optional\n            If True, print rewiring action, by default False\n        \"\"\"\n        # Select action: return a list of the probabilities of each action\n        action_rl = self.select_action(self.obs)\n        torch.cuda.empty_cache()\n        # Save rewiring action if we are testing\n        if test:\n            edge = (self.env.node_target, action_rl)\n            if edge in self.env.possible_actions[\"ADD\"]:\n                if not self.env.graph.has_edge(*edge):\n                    self.action_list[\"ADD\"].append(edge)\n            elif edge in self.env.possible_actions[\"REMOVE\"]:\n                if self.env.graph.has_edge(*edge):\n                    self.action_list[\"REMOVE\"].append(edge)\n        # Take action in environment\n        self.obs, reward, self.done, self.goal = self.env.step(action_rl)\n\n        # Update ra_losseward\n        self.episode_reward += reward\n        # Store the transition in memory, used for the training step\n        self.rewards.append(reward)\n        # Used for logging\n        self.episode_rewards.append(reward)\n        self.step += 1\n\n    def select_action(self, state: Data) -> int:\n        \"\"\"\n        Select action, given a state, using the policy network.\n        \n        Parameters\n        ----------\n        state : Data\n            Graph state\n        \n        Returns\n        -------\n        action: int\n            Integer representing a node in the graph, it will be the destination\n            node of the rewiring action\n        \"\"\"\n        concentration, value = self.policy(state)\n        dist = torch.distributions.Categorical(concentration)\n        action = dist.sample()\n        self.saved_actions.append(\n            self.SavedAction(dist.log_prob(action), value))\n        return int(action.item())\n\n    def training_step(self) -> Tuple[float, float]:\n        \"\"\"\n        Perform a single training step of the A2C algorithm, which involves\n        computing the actor and critic losses, taking gradient steps, and \n        resetting the rewards and action buffer.\n        \n        Returns\n        -------\n        mean_a_loss : float\n            Mean actor loss\n        mean_v_loss : float\n            Mean critic loss\n        \"\"\"\n        R = 0\n        saved_actions = self.saved_actions\n        policy_losses = []  # list to save actor (policy) loss\n        value_losses = []  # list to save critic (value) loss\n        returns = []  # list to save the true values\n        # Compute the true value using rewards returned from the environment\n        for r in self.rewards[::-1]:\n            # calculate the discounted value\n            R = r + self.gamma * R\n            # insert to the beginning of the list\n            returns.insert(0, R)\n        # Normalize returns by subtracting mean and dividing by standard deviation\n        # NOTE: May cause NaN problem\n        if len(returns) > 1:\n            returns = torch.tensor(returns)\n            returns = (returns - returns.mean()) / (returns.std() + self.eps)\n        else:\n            returns = torch.tensor(returns)\n        # Computing losses\n        for (log_prob, value), R in zip(saved_actions, returns):\n            # Difference between true value and estimated value from critic\n            advantage = R - value.item()\n            # calculate actor (policy) loss\n            policy_losses.append(-log_prob * advantage)\n            # calculate critic (value) loss using L1 smooth loss\n            value_losses.append(F.smooth_l1_loss(\n                value, torch.tensor([R]).to(self.device)))\n        # take gradient steps\n        self.optimizers['a_optimizer'].zero_grad()\n        a_loss = torch.stack(policy_losses).sum()\n        a_loss.backward()\n        self.optimizers['a_optimizer'].step()\n        self.optimizers['c_optimizer'].zero_grad()\n        v_loss = torch.stack(value_losses).sum()\n        v_loss.backward()\n        self.optimizers['c_optimizer'].step()\n        # Compute mean losses\n        mean_a_loss = torch.stack(policy_losses).mean().item()\n        mean_v_loss = torch.stack(value_losses).mean().item()\n        # reset rewards and action buffer\n        del self.rewards[:]\n        del self.saved_actions[:]\n        return mean_a_loss, mean_v_loss\n\n    ############################################################################\n    #                               TEST                                       #\n    ############################################################################\n    def test(\n            self,\n            lr: float,\n            gamma: float,\n            lambda_metric: float,\n            alpha_metric: float,\n            model_path: str) -> nx.Graph:\n        \"\"\"Hide a given node from a given community\"\"\"\n        # Set hyperparameters to select the correct folder\n        self.reset_hyperparams(lr, gamma, lambda_metric, alpha_metric, True)\n        # Load best performing model\n        self.load_checkpoint(path=model_path)\n        # Set model in evaluation mode\n        self.policy.eval()\n        self.obs = self.env.reset()\n        # Rewiring the graph until the target node is isolated from the\n        # target community\n        while not self.done and self.step < self.env.max_steps:\n            self.rewiring(test=True)\n        # if self.step >= self.env.max_steps:\n        #    print(\"* !!!Maximum number of steps reached!!!\")\n        return self.obs\n\n    ############################################################################\n    #                            CHECKPOINTING                                 #\n    ############################################################################\n    def get_path(self) -> str:\n        \"\"\"\n        Return the path of the folder where to save the plots and the logs\n        \n        Returns\n        -------\n        file_path : str\n            Path to the correct folder\n        \"\"\"\n        file_path = FilePaths.LOG_DIR.value + \\\n            f\"{self.env.env_name}/{self.env.detection_alg}/\" +\\\n            f\"lr-{self.lr}/gamma-{self.gamma}/\" +\\\n            f\"lambda-{self.env.lambda_metric}/alpha-{self.env.alpha_metric}\"\n        return file_path\n\n    def save_plots(self, log: dict, file_path: str) -> None:\n        \"\"\"\n        Save training plots and logs\n\n        Parameters\n        ----------\n        log : dict\n            Dict containing the training logs\n        file_path : str\n            Path to the directory where to save the plots and the logs\n        \"\"\"\n        Utils.check_dir(file_path)\n        self.log(log)\n        Utils.plot_training(\n            log,\n            self.env.env_name,\n            self.env.detection_alg,\n            file_path)\n\n    def save_checkpoint(self, best=False):\n        \"\"\"Save checkpoint\"\"\"\n        log_dir = self.get_path()\n        # Check if the directory exists, otherwise create it\n        Utils.check_dir(log_dir)\n        checkpoint = dict()\n        checkpoint['model'] = self.policy.state_dict()\n        for key, value in self.optimizers.items():\n            checkpoint[key] = value.state_dict()\n        if best:\n            path = f'{log_dir}/best_model.pth'\n        else:\n            path = f'{log_dir}/model.pth'\n        torch.save(checkpoint, path)\n\n    def load_checkpoint(self, path=None):\n        \"\"\"Load checkpoint\"\"\"\n        if path is None:\n            log_dir = self.get_path()\n            path = f'{log_dir}/model.pth'\n        checkpoint = torch.load(path, map_location=self.device)\n        self.policy.load_state_dict(checkpoint['model'])\n        for key, _ in self.optimizers.items():\n            self.optimizers[key].load_state_dict(checkpoint[key])\n\n    def log(self, log_dict: dict):\n        \"\"\"Log data\n        \n        Parameters\n        ----------\n        log_dict : dict\n            Dictionary containing the data to be logged\n        \"\"\"\n        log_dir = self.get_path()\n        Utils.check_dir(log_dir)\n        file_name = f'{log_dir}/training_results.json'\n        with open(file_name, \"w\", encoding=\"utf-8\") as f:\n            json.dump(log_dict, f, indent=4)\n\n    ############################################################################\n    #                   AGENT INFO AND PRINTING                                #\n    ############################################################################\n    def print_agent_info(self):\n        # Print model architecture\n        print(\"*\", \"-\"*18, \" Model Architecture \", \"-\"*18)\n        # print(\"* Embedding dimension: \", self.state_dim)\n        print(\"* Features vector size: \", self.state_dim)\n        print(\"* A2C Hidden layer 1 size: \", self.hidden_size_1)\n        print(\"* A2C Hidden layer 2 size: \", self.hidden_size_2)\n        print(\"* Actor Action dimension: \", self.action_dim)\n        print(\"*\", \"-\"*58, \"\\n\")\n        # Print Hyperparameters List\n        print(\"*\", \"-\"*18, \"Hyperparameters List\", \"-\"*18)\n        print(\"* Learning rate list: \", self.lr_list)\n        print(\"* Gamma parameter list: \", self.gamma_list)\n        print(\"* Lambda Metric list: \", self.lambda_metrics)\n        print(\"* Alpha Metric list: \", self.alpha_metrics)\n        print(\"*\", \"-\"*58, \"\\n\")\n\n    def print_hyperparams(self):\n        print(\"*\", \"-\"*18, \"Model Hyperparameters\", \"-\"*18)\n        print(\"* Learning rate: \", self.lr)\n        print(\"* Gamma parameter: \", self.gamma)\n        print(\"* Lambda Metric: \", self.env.lambda_metric)\n        print(\"* Alpha Metric: \", self.env.alpha_metric)\n        print(\"* Value for clipping the loss function: \", self.eps)","metadata":{"id":"KUntGR5MGjVD","execution":{"iopub.status.busy":"2023-09-20T08:40:48.060781Z","iopub.execute_input":"2023-09-20T08:40:48.061087Z","iopub.status.idle":"2023-09-20T08:40:48.128277Z","shell.execute_reply.started":"2023-09-20T08:40:48.061060Z","shell.execute_reply":"2023-09-20T08:40:48.127276Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"markdown","source":"### A2C","metadata":{"_cell_guid":"bdb2c8bd-ec95-4293-b9be-70ecfa9f3c1b","_uuid":"065700a9-c782-4a92-8abb-06cbb83acf28","id":"1S7ubGoY4qN4","trusted":true}},{"cell_type":"code","source":"class ActorCritic(nn.Module):\n    \"\"\"ActorCritic Network\"\"\"\n\n    def __init__(\n        self,\n        state_dim: int,\n        hidden_size_1: int,\n        hidden_size_2: int,\n        action_dim: int,\n        graph: nx.Graph):\n        super(ActorCritic, self).__init__()\n        self.actor = ActorNetwork(\n            state_dim=state_dim,\n            hidden_size_1=hidden_size_1,\n            hidden_size_2=hidden_size_2,\n            action_dim=action_dim\n        )\n        self.critic = CriticNetwork(\n            state_dim=state_dim,\n            hidden_size_1=hidden_size_1,\n            hidden_size_2=hidden_size_2\n        )\n        self.device = torch.device(\n            'cuda:0' if torch.cuda.is_available() else 'cpu')\n\n    def forward(self, graph: nx.Graph, jitter=1e-20) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Forward pass, computes action and value\n\n        Parameters\n        ----------\n        graph : nx.Graph\n            Graph state\n        jitter : float, optional\n            Jitter value, by default 1e-20\n\n        Returns\n        -------\n        Tuple[torch.Tensor, torch.Tensor]\n            Tuple of concentration and value\n        \"\"\"\n        # Compute embedding\n        # Uncomment to use CGNConv\n        state = from_networkx(graph).to(self.device)\n        # Uncomment to use GL2Vec\n        # state = torch.tensor(self.model.infer([graph])).to(self.device)\n        # Actor\n        probs = self.actor(state)\n        # Use softplus to ensure concentration is positive, then add jitter to \n        # ensure numerical stability\n        concentration = F.softplus(probs).reshape(-1) + jitter\n        # get index of max concentration\n        # Critic\n        value = self.critic(state)\n        return concentration, value","metadata":{"id":"Klrf4zrpGsc_","execution":{"iopub.status.busy":"2023-09-20T08:40:48.130025Z","iopub.execute_input":"2023-09-20T08:40:48.130536Z","iopub.status.idle":"2023-09-20T08:40:48.144134Z","shell.execute_reply.started":"2023-09-20T08:40:48.130501Z","shell.execute_reply":"2023-09-20T08:40:48.143302Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"markdown","source":"#### Actor","metadata":{"_cell_guid":"c5de2a68-f7d0-4f19-9b0d-44279dbe451a","_uuid":"086c55ba-63e2-4ea2-8739-4b6e3827771a","id":"SfScUOtU4qN4","trusted":true}},{"cell_type":"code","source":"class ActorNetwork(nn.Module):\n    \"\"\"Actor Network\"\"\"\n\n    def __init__(\n            self,\n            state_dim: int,\n            hidden_size_1: int,\n            hidden_size_2: int,\n            action_dim: int):\n        super(ActorNetwork, self).__init__()\n\n        # self.graph_encoder = GraphEncoder(state_dim)\n        \n        self.conv1 = GCNConv(state_dim, state_dim)\n        self.lin1 = nn.Linear(state_dim, hidden_size_1)\n        self.lin2 = nn.Linear(hidden_size_1, hidden_size_2)\n        # self.lin3 = nn.Linear(hidden_size_2, action_dim)\n        self.lin3 = nn.Linear(hidden_size_2, 1)\n\n        # self.relu = nn.LeakyReLU()\n        self.relu = nn.ReLU()\n        # self.tanh = nn.Tanh()\n\n    def forward(self, data: torch.Tensor)->torch.Tensor:\n        out = F.relu(self.conv1(data.x, data.edge_index))\n        x = out + data.x\n        # x = F.relu(self.lin1(data))\n        x = F.relu(self.lin1(x))\n        x = F.relu(self.lin2(x))\n        x = self.lin3(x)\n        return x","metadata":{"_cell_guid":"12372f56-95f9-4f14-b708-b925514768fb","_uuid":"ad385add-1ff5-49eb-96ae-35dfa1f62ebc","collapsed":false,"id":"HV4Ef1504qN4","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-20T08:40:48.145334Z","iopub.execute_input":"2023-09-20T08:40:48.146183Z","iopub.status.idle":"2023-09-20T08:40:48.161345Z","shell.execute_reply.started":"2023-09-20T08:40:48.146155Z","shell.execute_reply":"2023-09-20T08:40:48.160261Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"markdown","source":"#### Critic","metadata":{"_cell_guid":"e2e118f7-d52d-4e73-997e-53a1a32afbe8","_uuid":"30ebc803-c985-4f23-95c4-3fc867216fde","id":"4L57IBdh4qN4","trusted":true}},{"cell_type":"code","source":"class CriticNetwork(nn.Module):\n    def __init__(\n            self,\n            state_dim: int,\n            hidden_size_1: int,\n            hidden_size_2: int):\n        super(CriticNetwork, self).__init__()\n\n        # self.graph_encoder = GraphEncoder(state_dim)\n        self.conv1 = GCNConv(state_dim, state_dim)\n\n        self.lin1 = nn.Linear(state_dim, hidden_size_1)\n        self.lin2 = nn.Linear(hidden_size_1, hidden_size_2)\n        self.lin3 = nn.Linear(hidden_size_2, 1)\n\n        # self.relu = nn.LeakyReLU()\n        self.relu = nn.ReLU()\n        # self.relu = F.relu\n        # self.tanh = nn.Tanh()\n\n    def forward(self, data: torch.Tensor)->torch.Tensor:\n        out = F.relu(self.conv1(data.x, data.edge_index))\n        x = out + data.x\n        x = torch.sum(x, dim=0)\n        # x = self.relu(self.lin1(data))\n        x = self.relu(self.lin1(x))\n        x = self.relu(self.lin2(x))\n        x = self.lin3(x)\n        return x","metadata":{"_cell_guid":"99f81ba0-98ed-4057-9476-259a0fd7f104","_uuid":"c10b6fa0-86d3-43fe-bfce-a7ef2ce8e457","collapsed":false,"id":"jRxY8xcL4qN4","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-20T08:40:48.164228Z","iopub.execute_input":"2023-09-20T08:40:48.164646Z","iopub.status.idle":"2023-09-20T08:40:48.183488Z","shell.execute_reply.started":"2023-09-20T08:40:48.164609Z","shell.execute_reply":"2023-09-20T08:40:48.182433Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"markdown","source":"## Test","metadata":{"id":"RA1YamymHWH7"}},{"cell_type":"code","source":"def test(\n    agent: Agent,\n    beta: float,\n    tau: float,\n    model_path: str,\n    eval_steps: int = HyperParams.STEPS_EVAL.value,\n    lr: float = HyperParams.LR_EVAL.value,\n    gamma: float = HyperParams.GAMMA_EVAL.value,\n    lambda_metric: float = HyperParams.LAMBDA_EVAL.value,\n    alpha_metric: float = HyperParams.ALPHA_EVAL.value)->None:\n    \"\"\"\n    Function to evaluate the performance of the agent and compare it with \n    the baseline algorithms.\n    \n    The baseline algorithms are:\n        - Random Hiding\n        - Degree Hiding\n        - Roam Heuristic\n\n    Parameters\n    ----------\n    agent : Agent\n        Agent to evaluate\n    beta : float\n        Beta parameter for the number of rewiring steps\n    tau : float\n        Tau parameter as constraint for community target similarity\n    model_path : str\n        Path to the model to load\n    eval_steps : int, optional\n        Number of episodes to test, by default 1000\n    lr : float, optional\n        Learning rate, by default 1e-3\n    gamma : float, optional\n        Discount factor, by default 0.3\n    lambda_metric : float, optional\n        Weight to balance the penalty and reward, by default 0.1\n    alpha_metric : float, optional\n        Weight to balance the penalties, by default 0.1\n    \"\"\"\n    # Initialize the log dictionary\n    log_dict = Utils.initialize_dict(HyperParams.ALGS_EVAL.value)\n    \n    # Set parameters in the environment\n    agent.env.beta = beta\n    agent.env.edge_budget = agent.env.get_edge_budget() * agent.env.beta\n    agent.env.max_steps = agent.env.edge_budget * HyperParams.MAX_STEPS_MUL.value\n    agent.env.tau = tau\n    \n        # Add environment parameters to the log dictionary\n    log_dict[\"env\"] = dict()\n    log_dict[\"env\"][\"dataset\"] = agent.env.env_name\n    log_dict[\"env\"][\"detection_alg\"] = agent.env.detection_alg\n    log_dict[\"env\"][\"beta\"] = beta\n    log_dict[\"env\"][\"tau\"] = tau\n    log_dict[\"env\"][\"edge_budget\"] = agent.env.edge_budget\n    log_dict[\"env\"][\"max_steps\"] = agent.env.max_steps\n    \n    # Add Agent Hyperparameters to the log dictionary\n    log_dict[\"Agent\"][\"lr\"] = lr\n    log_dict[\"Agent\"][\"gamma\"] = gamma\n    log_dict[\"Agent\"][\"lambda_metric\"] = lambda_metric\n    log_dict[\"Agent\"][\"alpha_metric\"] = alpha_metric\n    \n    # Start evaluation\n    steps = trange(eval_steps, desc=\"Testing Episode\")\n    for step in steps:\n        \n        # Change the target community and node at each episode\n        agent.env.change_target_community()\n        \n        # ° ------ Agent ------ ° #\n        steps.set_description(f\"* Testing Episode {step+1} | Agent Rewiring\")\n        start = time.time()\n        new_graph = agent.test(\n            lr=lr,\n            gamma=gamma,\n            lambda_metric=lambda_metric,\n            alpha_metric= alpha_metric,\n            model_path=model_path,\n        )\n        # \"src/logs/lfr_benchmark_n-300/infomap/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7\"\n        end = time.time() - start\n        \n        # ° Target node and community for this episode ° #\n        # We set it after the test to change automatically at each episode\n        community_structure = agent.env.original_community_structure\n        community_target = agent.env.community_target\n        node_target = agent.env.node_target\n        # ° ------------------------------------------ ° #\n        # Get new target community after deception\n        agent_community = Utils.get_new_community(node_target, agent.env.new_community_structure)\n        # Compute NMI between the new community structure and the original one\n        agent_nmi = community_structure.normalized_mutual_information(\n            agent.env.new_community_structure).score\n        # Check if the goal of hiding the target node was achieved\n        agent_goal = Utils.check_goal(agent.env, node_target, community_target, agent_community)\n        # Save the metrics\n        log_dict = save_metrics(\n            log_dict, \"Agent\", agent_goal, agent_nmi, end, agent.step)\n\n        \n        # Perform Deception with the baseline algorithms\n        # ° ------ Random Hiding ------ ° #\n        steps.set_description(f\"* Testing Episode {step+1} | Random Rewiring\")\n        random_hiding = RandomHiding(\n            env=agent.env,\n            steps=agent.env.edge_budget,\n            target_community=community_target)\n\n        start = time.time()\n        rh_graph, rh_communities = random_hiding.hide_target_node_from_community()\n        end = time.time() - start\n        \n        # Get new target community after deception\n        rh_community = Utils.get_new_community(node_target, rh_communities)\n        # Compute NMI between the new community structure and the original one\n        rh_nmi = community_structure.normalized_mutual_information(\n            rh_communities).score\n        # Check if the goal of hiding the target node was achieved\n        rh_goal = Utils.check_goal(\n            agent.env, node_target, community_target, rh_community)\n        # Save the metrics\n        log_dict = save_metrics(\n            log_dict, \"Random\", rh_goal, rh_nmi, end, agent.env.edge_budget-random_hiding.steps)\n        \n\n        # ° ------ Degree Hiding ------ ° #\n        steps.set_description(f\"* Testing Episode {step+1} | Degree Rewiring\")\n        degree_hiding = DegreeHiding(\n            env=agent.env,\n            steps=agent.env.edge_budget,\n            target_community=community_target)\n\n        start = time.time()\n        dh_graph, dh_communities = degree_hiding.hide_target_node_from_community()\n        end = time.time() - start\n        \n        # Get new target community after deception\n        dh_community = Utils.get_new_community(node_target, dh_communities)\n        # Compute NMI between the new community structure and the original one\n        dh_nmi = community_structure.normalized_mutual_information(\n            dh_communities).score\n        # Check if the goal of hiding the target node was achieved\n        dh_goal = Utils.check_goal(\n            agent.env, node_target, community_target, dh_community)\n        # Save the metrics\n        log_dict = save_metrics(\n            log_dict, \"Degree\", dh_goal, dh_nmi, end, agent.env.edge_budget-degree_hiding.steps)\n\n        # ° ------ Roam Heuristic ------ ° #\n        steps.set_description(f\"* Testing Episode {step+1} | Roam Rewiring\")\n        # Apply Hide and Seek\n        deception = RoamHiding(\n            agent.env.original_graph.copy(), node_target, agent.env.detection_alg)\n        start = time.time()\n        di_graph, di_communities = deception.roam_heuristic(\n            agent.env.edge_budget)\n        end = time.time() - start\n        \n        # Get new target community after deception\n        di_community = Utils.get_new_community(node_target, di_communities)\n        # Compute NMI between the new community structure and the original one\n        di_nmi = community_structure.normalized_mutual_information(\n            di_communities).score\n        # Check if the goal of hiding the target node was achieved\n        di_goal = Utils.check_goal(\n            agent.env, node_target, community_target, di_community)\n        # Save the metrics\n        log_dict = save_metrics(\n            log_dict, \"Roam\", di_goal, di_nmi, end, agent.env.edge_budget)\n\n        steps.set_description(f\"* Testing Episode {step+1}\")\n    # Save the log\n    path = FilePaths.TEST_DIR.value + \\\n        f\"{log_dict['env']['dataset']}/{log_dict['env']['detection_alg']}/\" + \\\n        f\"tau-{tau}/beta-{beta}/\" + \\\n        f\"lr-{lr}/gamma-{gamma}/lambda-{lambda_metric}/alpha-{alpha_metric}/\"\n    Utils.check_dir(path)\n    Utils.save_test(log_dict, path)\n\n\n################################################################################\n#                               Utility Functions                              #\n################################################################################\ndef save_metrics(\n        log_dict: dict, alg: str, goal: int,\n        nmi: float, time: float, steps: int) -> dict:\n    \"\"\"Save the metrics of the algorithm in the log dictionary\"\"\"\n    log_dict[alg][\"goal\"].append(goal)\n    log_dict[alg][\"nmi\"].append(nmi)\n    log_dict[alg][\"time\"].append(time)\n    log_dict[alg][\"steps\"].append(steps)\n    return log_dict\n","metadata":{"id":"rwAhTuYBHXt6","execution":{"iopub.status.busy":"2023-09-20T08:40:48.185340Z","iopub.execute_input":"2023-09-20T08:40:48.186013Z","iopub.status.idle":"2023-09-20T08:40:48.214973Z","shell.execute_reply.started":"2023-09-20T08:40:48.185976Z","shell.execute_reply":"2023-09-20T08:40:48.214139Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"markdown","source":"## Execution","metadata":{"_cell_guid":"3d97430f-a01e-43dc-b176-9c89aeba9b76","_uuid":"5d0f3e09-b452-468d-88ec-3d86fe84bc84","id":"Pnf9azpI4qN6","trusted":true}},{"cell_type":"code","source":"# NOTE To modify the hyperparameters, dataset, detection algorithm, etc. \n# NOTE  please refer to the file src/utils/utils.py in the class HyperParams\n# ° --- Environment Setup --- ° #\nenv = GraphEnvironment()\n# ° ------ Agent Setup ----- ° #\nagent = Agent(env=env)","metadata":{"_cell_guid":"51cf9745-acf7-4dda-86e8-d2af6379b330","_uuid":"0a274b78-6920-44c3-a17e-2b0c3b9261f9","collapsed":false,"id":"f6HA13XSGqAn","jupyter":{"outputs_hidden":false},"outputId":"e92633ec-3abf-4870-ccbb-e9d3a5db9b87","scrolled":true,"execution":{"iopub.status.busy":"2023-09-20T08:40:48.216547Z","iopub.execute_input":"2023-09-20T08:40:48.217215Z","iopub.status.idle":"2023-09-20T08:40:48.264728Z","shell.execute_reply.started":"2023-09-20T08:40:48.217178Z","shell.execute_reply":"2023-09-20T08:40:48.263653Z"},"trusted":true},"execution_count":114,"outputs":[{"name":"stdout","text":"******************** Environment Information ********************\n* Graph Name: kar\n* Graph with 34 nodes and 78 edges\n* Community Detection Algorithm: greedy\n* Number of communities found: 3\n* Rewiring Budget: (Number of Nodes / Number of Edges) * BETA = 34 / 78 * 3 = 6\n* Weight of the Deception Constraint: 0.5\n* ---------------------------------------------------------- \n\n* ------------------  Model Architecture  ------------------\n* Features vector size:  2\n* A2C Hidden layer 1 size:  64\n* A2C Hidden layer 2 size:  64\n* Actor Action dimension:  34\n* ---------------------------------------------------------- \n\n* ------------------ Hyperparameters List ------------------\n* Learning rate list:  [0.0001]\n* Gamma parameter list:  [0.9]\n* Lambda Metric list:  [0.1]\n* Alpha Metric list:  [0.7]\n* ---------------------------------------------------------- \n\n","output_type":"stream"}]},{"cell_type":"code","source":"# ° ------ TRAIN ------ ° #\nif TRAIN:\n    # Training\n    agent.grid_search()","metadata":{"id":"WyhvK6r8P2Jb","outputId":"7426cdb5-8913-4bdd-fd1f-4864994fb49d","execution":{"iopub.status.busy":"2023-09-20T08:40:48.266137Z","iopub.execute_input":"2023-09-20T08:40:48.266472Z","iopub.status.idle":"2023-09-20T08:40:48.271378Z","shell.execute_reply.started":"2023-09-20T08:40:48.266444Z","shell.execute_reply":"2023-09-20T08:40:48.270111Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"# !zip -r file_logs.zip /kaggle/working/logs/\n# FileLink(r'file_logs.zip')","metadata":{"execution":{"iopub.status.busy":"2023-09-20T08:40:48.272852Z","iopub.execute_input":"2023-09-20T08:40:48.274044Z","iopub.status.idle":"2023-09-20T08:40:48.284043Z","shell.execute_reply.started":"2023-09-20T08:40:48.274012Z","shell.execute_reply":"2023-09-20T08:40:48.283212Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"# ° ------ TEST ------ ° #\nif TEST:\n    model_path = FilePaths.TRAINED_MODEL.value\n    betas = [1,3,5]\n    taus = [0.3, 0.5, 0.8]\n    for beta in betas:\n        for tau in taus:\n            test(agent=agent, model_path=model_path, beta=beta, tau= tau)","metadata":{"id":"wKP3Qy24P7OT","outputId":"35ce27f0-5a6c-4998-acfe-e5d07b36c260","execution":{"iopub.status.busy":"2023-09-20T08:40:48.286634Z","iopub.execute_input":"2023-09-20T08:40:48.286940Z","iopub.status.idle":"2023-09-20T09:17:50.214353Z","shell.execute_reply.started":"2023-09-20T08:40:48.286912Z","shell.execute_reply":"2023-09-20T09:17:50.213282Z"},"trusted":true},"execution_count":117,"outputs":[{"name":"stderr","text":"* Testing Episode 1000: 100%|██████████| 1000/1000 [02:22<00:00,  7.03it/s]                 \n* Testing Episode 1000: 100%|██████████| 1000/1000 [02:22<00:00,  7.00it/s]                 \n* Testing Episode 1000: 100%|██████████| 1000/1000 [02:21<00:00,  7.08it/s]                 \n* Testing Episode 1000: 100%|██████████| 1000/1000 [04:38<00:00,  3.59it/s]                 \n* Testing Episode 1000: 100%|██████████| 1000/1000 [04:25<00:00,  3.76it/s]                 \n* Testing Episode 1000: 100%|██████████| 1000/1000 [04:10<00:00,  3.99it/s]                 \n* Testing Episode 1000: 100%|██████████| 1000/1000 [06:15<00:00,  2.66it/s]                 \n* Testing Episode 1000: 100%|██████████| 1000/1000 [05:45<00:00,  2.89it/s]                 \n* Testing Episode 1000: 100%|██████████| 1000/1000 [04:32<00:00,  3.67it/s]                 \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 0 Axes>"},"metadata":{}}]},{"cell_type":"code","source":"!zip -r file_test.zip /kaggle/working/test/\nFileLink(r'file_test.zip')","metadata":{"execution":{"iopub.status.busy":"2023-09-20T09:17:50.215563Z","iopub.execute_input":"2023-09-20T09:17:50.215859Z","iopub.status.idle":"2023-09-20T09:17:51.420106Z","shell.execute_reply.started":"2023-09-20T09:17:50.215832Z","shell.execute_reply":"2023-09-20T09:17:51.418777Z"},"trusted":true},"execution_count":118,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/test/ (stored 0%)\n  adding: kaggle/working/test/kar/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-5/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-5/lr-0.0001/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-5/lr-0.0001/gamma-0.9/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-5/lr-0.0001/gamma-0.9/lambda-0.1/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-5/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-5/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/nmi.png (deflated 21%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-5/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/goal.png (deflated 21%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-5/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/time.png (deflated 20%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-5/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/evaluation_results.json (deflated 87%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-5/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/steps.png (deflated 19%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-3/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-3/lr-0.0001/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-3/lr-0.0001/gamma-0.9/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-3/lr-0.0001/gamma-0.9/lambda-0.1/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-3/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-3/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/nmi.png (deflated 21%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-3/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/goal.png (deflated 20%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-3/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/time.png (deflated 20%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-3/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/evaluation_results.json (deflated 87%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-3/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/steps.png (deflated 20%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-1/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-1/lr-0.0001/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-1/lr-0.0001/gamma-0.9/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-1/lr-0.0001/gamma-0.9/lambda-0.1/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-1/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-1/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/nmi.png (deflated 20%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-1/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/goal.png (deflated 20%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-1/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/time.png (deflated 21%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-1/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/evaluation_results.json (deflated 88%)\n  adding: kaggle/working/test/kar/greedy/tau-0.5/beta-1/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/steps.png (deflated 20%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-5/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-5/lr-0.0001/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-5/lr-0.0001/gamma-0.9/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-5/lr-0.0001/gamma-0.9/lambda-0.1/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-5/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-5/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/nmi.png (deflated 21%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-5/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/goal.png (deflated 20%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-5/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/time.png (deflated 21%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-5/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/evaluation_results.json (deflated 87%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-5/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/steps.png (deflated 20%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-3/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-3/lr-0.0001/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-3/lr-0.0001/gamma-0.9/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-3/lr-0.0001/gamma-0.9/lambda-0.1/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-3/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-3/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/nmi.png (deflated 21%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-3/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/goal.png (deflated 20%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-3/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/time.png (deflated 21%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-3/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/evaluation_results.json (deflated 87%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-3/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/steps.png (deflated 20%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-1/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-1/lr-0.0001/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-1/lr-0.0001/gamma-0.9/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-1/lr-0.0001/gamma-0.9/lambda-0.1/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-1/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-1/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/nmi.png (deflated 20%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-1/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/goal.png (deflated 21%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-1/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/time.png (deflated 20%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-1/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/evaluation_results.json (deflated 88%)\n  adding: kaggle/working/test/kar/greedy/tau-0.3/beta-1/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/steps.png (deflated 20%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-5/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-5/lr-0.0001/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-5/lr-0.0001/gamma-0.9/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-5/lr-0.0001/gamma-0.9/lambda-0.1/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-5/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-5/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/nmi.png (deflated 21%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-5/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/goal.png (deflated 20%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-5/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/time.png (deflated 21%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-5/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/evaluation_results.json (deflated 87%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-5/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/steps.png (deflated 20%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-3/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-3/lr-0.0001/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-3/lr-0.0001/gamma-0.9/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-3/lr-0.0001/gamma-0.9/lambda-0.1/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-3/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-3/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/nmi.png (deflated 21%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-3/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/goal.png (deflated 20%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-3/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/time.png (deflated 21%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-3/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/evaluation_results.json (deflated 87%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-3/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/steps.png (deflated 20%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-1/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-1/lr-0.0001/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-1/lr-0.0001/gamma-0.9/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-1/lr-0.0001/gamma-0.9/lambda-0.1/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-1/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/ (stored 0%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-1/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/nmi.png (deflated 20%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-1/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/goal.png (deflated 20%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-1/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/time.png (deflated 21%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-1/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/evaluation_results.json (deflated 88%)\n  adding: kaggle/working/test/kar/greedy/tau-0.8/beta-1/lr-0.0001/gamma-0.9/lambda-0.1/alpha-0.7/steps.png (deflated 20%)\n","output_type":"stream"},{"execution_count":118,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/file_test.zip","text/html":"<a href='file_test.zip' target='_blank'>file_test.zip</a><br>"},"metadata":{}}]}]}