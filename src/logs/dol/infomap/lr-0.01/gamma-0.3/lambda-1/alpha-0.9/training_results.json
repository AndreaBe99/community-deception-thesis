{
    "train_reward": [
        0.8144703228868498,
        -0.5609408820549354,
        -11.854538032745793,
        -0.5311909908222847,
        0.4732648861035541,
        0.507878526128839,
        -4.088034056438276,
        -1.0136434224573405,
        -2.74621861842303,
        0.507878526128839
    ],
    "train_steps": [
        1,
        5,
        28,
        2,
        1,
        1,
        19,
        10,
        17,
        1
    ],
    "train_avg_reward": [
        0.8144703228868498,
        -0.11218817641098708,
        -0.42337635831234977,
        -0.26559549541114236,
        0.4732648861035541,
        0.507878526128839,
        -0.21515968718096187,
        -0.10136434224573405,
        -0.16154227167194293,
        0.507878526128839
    ],
    "a_loss": [
        3.6795403048513626,
        0.23121180378174774,
        0.11816311608885843,
        0.16693951097031268,
        2.2161061110160216,
        2.381554719470521,
        0.2911796842641106,
        0.2773485932022842,
        0.20339611816977157,
        2.3567443349462787
    ],
    "v_loss": [
        0.42533903161396003,
        0.3862001160014245,
        0.3938148677331763,
        0.2508519927147005,
        0.1427179023502404,
        0.1665856623681299,
        0.3904925579926692,
        0.41255336815733556,
        0.4043094285184874,
        0.15258155161571554
    ],
    "train_episodes": 10
}