{
    "train_reward": [
        0.9950313246021042,
        0.9915356954840845,
        0.9917517266691688,
        0.9926467243318042,
        -1.0071452107036245,
        -1.0080529774964688,
        0.9936662873184339,
        -3.0059706843807046,
        -1.0177399459031227,
        -9.010559516536382
    ],
    "train_steps": [
        2,
        1,
        2,
        1,
        9,
        2,
        4,
        4,
        6,
        8
    ],
    "train_avg_reward": [
        0.4975156623010521,
        0.9915356954840845,
        0.4958758633345844,
        0.9926467243318042,
        -0.11190502341151383,
        -0.5040264887482344,
        0.24841657182960847,
        -0.7514926710951761,
        -0.1696233243171871,
        -1.1263199395670478
    ],
    "a_loss": [
        0.2877350327352237,
        3.619302262862383,
        0.26753051042256537,
        3.8382668647792104,
        0.1667849139962002,
        0.16185895088243019,
        0.19551139056222766,
        0.10811013407442893,
        0.17073740456148423,
        0.1353466161132813
    ],
    "v_loss": [
        0.2522291033380545,
        0.557675520172519,
        0.25183766136850594,
        0.5521278124038658,
        0.346671247930368,
        0.25135260325494635,
        0.34512482097806857,
        0.374950777358913,
        0.36745555088585197,
        0.380395075459031
    ],
    "train_episodes": 10
}