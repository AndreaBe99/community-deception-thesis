{
    "train_reward": [
        0.9827756311046868,
        -5.013021662831772,
        -25.019226150824863,
        -53.01227823408791,
        -73.00305560549492,
        -154.01608168154507,
        -156,
        -156,
        -156,
        -156
    ],
    "train_steps": [
        4,
        9,
        20,
        34,
        41,
        78,
        78,
        78,
        78,
        78
    ],
    "train_avg_reward": [
        0.2456939077761717,
        -0.557002406981308,
        -1.2509613075412431,
        -1.559184653943762,
        -1.7805623318413395,
        -1.9745651497633985,
        -2.0,
        -2.0,
        -2.0,
        -2.0
    ],
    "a_loss": [
        -0.1613916568115732,
        -0.14977671459766206,
        -0.11321671949667107,
        -0.10532358413405596,
        -0.07889721337458093,
        -0.04895464577399945,
        -0.058066368103027344,
        -0.030510621145367622,
        -0.004569652955979109,
        0.0040508052334189415
    ],
    "v_loss": [
        0.355638415093366,
        0.4058297244786294,
        0.4550643216257467,
        0.4253918226597658,
        0.3028266673297048,
        0.17444534779452617,
        0.13973715901374817,
        0.13907082378864288,
        0.13840331137180328,
        0.13775768876075745
    ],
    "train_episodes": 10
}