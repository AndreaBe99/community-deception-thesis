{
    "train_reward": [
        -3.012969523794349,
        0.9896394962295725,
        -5.011417529640518,
        -17.0095026079366,
        -33.01814702396506,
        -53.01493608519702,
        -11.013534410330202,
        -152.00030927835053,
        -156,
        -156
    ],
    "train_steps": [
        6,
        2,
        7,
        15,
        22,
        32,
        8,
        78,
        78,
        78
    ],
    "train_avg_reward": [
        -0.5021615872990581,
        0.49481974811478624,
        -0.7159167899486454,
        -1.1339668405291066,
        -1.5008248647256843,
        -1.656716752662407,
        -1.3766918012912752,
        -1.9487219138250067,
        -2.0,
        -2.0
    ],
    "a_loss": [
        0.5937993443878566,
        0.5195887114600647,
        0.5016657291309209,
        0.5412047251175206,
        0.5072644519515674,
        0.5010838218016738,
        0.5181073048985794,
        0.5022977096889866,
        0.5331441164016724,
        0.539193332195282
    ],
    "v_loss": [
        0.3658082724755695,
        0.2615892393949793,
        0.36587283222750494,
        0.4365006231901969,
        0.38694390509518367,
        0.389051986822438,
        0.3996469449079565,
        0.3194868054037155,
        0.3226591944694519,
        0.3225313723087311
    ],
    "train_episodes": 10
}