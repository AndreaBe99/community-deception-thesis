{
    "train_reward": [
        0.9807409115622774,
        -1.0049483851603405,
        -1.01734813763332,
        -7.019088351837872,
        0.9923120470569875,
        -1.0152046855279022,
        -1.0080165440505646,
        -1.0221564526197957,
        0.9885900167170122,
        -13.02490118659759
    ],
    "train_steps": [
        3,
        3,
        3,
        7,
        4,
        2,
        5,
        4,
        2,
        10
    ],
    "train_avg_reward": [
        0.3269136371874258,
        -0.3349827950534468,
        -0.33911604587777333,
        -1.0027269074054102,
        0.24807801176424688,
        -0.5076023427639511,
        -0.20160330881011293,
        -0.2555391131549489,
        0.4942950083585061,
        -1.302490118659759
    ],
    "a_loss": [
        0.37311956052288603,
        0.37799983568769946,
        0.32850600753019615,
        0.27264130712416973,
        0.37543382102768597,
        0.26037244231939627,
        0.335065572747182,
        0.34310757670741476,
        0.24222317693713835,
        0.25461663877306306
    ],
    "v_loss": [
        0.3398685312245144,
        0.32768836522822437,
        0.33831581704710884,
        0.392847585622732,
        0.365523953632849,
        0.25420402044038914,
        0.3970208749572405,
        0.37825133707360503,
        0.2528152636001043,
        0.4272004383275849
    ],
    "train_episodes": 10
}